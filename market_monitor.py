
import pandas as pd
import numpy as np
import re
import os
import logging
from datetime import datetime, timedelta, time
import random
from io import StringIO
import requests
import tenacity
import concurrent.futures
import time as time_module

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('market_monitor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å®šä¹‰æœ¬åœ°æ•°æ®å­˜å‚¨ç›®å½•
DATA_DIR = 'fund_data'
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

class MarketMonitor:
    def __init__(self, report_file='analysis_report.md', output_file='market_monitor_report.md', backtest_output_file='backtest_report.md'):
        self.report_file = report_file
        self.output_file = output_file
        self.backtest_output_file = backtest_output_file
        self.fund_codes = []
        self.fund_data = {}
        self.index_code = '000300'  # æ²ªæ·±300æŒ‡æ•°ä»£ç 
        self.index_data = {}
        self.index_df = pd.DataFrame()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36'
        }

    def _get_expected_latest_date(self):
        """æ ¹æ®å½“å‰æ—¶é—´ç¡®å®šæœŸæœ›çš„æœ€æ–°æ•°æ®æ—¥æœŸ"""
        now = datetime.now()
        # å‡è®¾å‡€å€¼æ›´æ–°æ—¶é—´ä¸ºæ™šä¸Š21:00
        update_time = time(21, 0)
        if now.time() < update_time:
            # å¦‚æœå½“å‰æ—¶é—´æ—©äº21:00ï¼Œåˆ™æœŸæœ›æœ€æ–°æ—¥æœŸä¸ºæ˜¨å¤©
            expected_date = now.date() - timedelta(days=1)
        else:
            # å¦åˆ™ï¼ŒæœŸæœ›æœ€æ–°æ—¥æœŸä¸ºä»Šå¤©
            expected_date = now.date()
        logger.info("å½“å‰æ—¶é—´: %s, æœŸæœ›æœ€æ–°æ•°æ®æ—¥æœŸ: %s", now.strftime('%Y-%m-%d %H:%M:%S'), expected_date)
        return expected_date

    def _parse_report(self, report_path='analysis_report.md'):
        """ä» analysis_report.md æå–æ¨èåŸºé‡‘ä»£ç """
        logger.info("æ­£åœ¨è§£æ %s è·å–æ¨èåŸºé‡‘ä»£ç ...", report_path)
        if not os.path.exists(report_path):
            logger.error("æŠ¥å‘Šæ–‡ä»¶ %s ä¸å­˜åœ¨", report_path)
            raise FileNotFoundError(f"{report_path} ä¸å­˜åœ¨")
        
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            pattern = re.compile(r'(?:^\| +(\d{6})|### åŸºé‡‘ (\d{6}))', re.M)
            matches = pattern.findall(content)

            extracted_codes = set()
            for match in matches:
                code = match[0] if match[0] else match[1]
                extracted_codes.add(code)
            
            sorted_codes = sorted(list(extracted_codes))
            self.fund_codes = sorted_codes[:10]
            
            if not self.fund_codes:
                logger.warning("æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆåŸºé‡‘ä»£ç ï¼Œè¯·æ£€æŸ¥ analysis_report.md")
            else:
                logger.info("æå–åˆ° %d ä¸ªåŸºé‡‘ï¼ˆæµ‹è¯•é™åˆ¶å‰10ä¸ªï¼‰: %s", len(self.fund_codes), self.fund_codes)
            
        except Exception as e:
            logger.error("è§£ææŠ¥å‘Šæ–‡ä»¶å¤±è´¥: %s", e)
            raise

    def _read_local_data(self, fund_code):
        """è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨åˆ™è¿”å›DataFrame"""
        file_path = os.path.join(DATA_DIR, f"{fund_code}.csv")
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path, parse_dates=['date'])
                if not df.empty and 'date' in df.columns and 'net_value' in df.columns:
                    df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
                    logger.info("æœ¬åœ°å·²å­˜åœ¨åŸºé‡‘ %s æ•°æ®ï¼Œå…± %d è¡Œï¼Œæœ€æ–°æ—¥æœŸä¸º: %s", fund_code, len(df), df['date'].max().date())
                    return df
            except Exception as e:
                logger.warning("è¯»å–æœ¬åœ°æ–‡ä»¶ %s å¤±è´¥: %s", file_path, e)
        return pd.DataFrame()

    def _save_to_local_file(self, fund_code, df):
        """å°†DataFrameä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œè¦†ç›–æ—§æ–‡ä»¶"""
        file_path = os.path.join(DATA_DIR, f"{fund_code}.csv")
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        df.to_csv(file_path, index=False)
        logger.info("åŸºé‡‘ %s æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶: %s", fund_code, file_path)

    @tenacity.retry(
        stop=tenacity.stop_after_attempt(5),
        wait=tenacity.wait_fixed(10),
        retry=tenacity.retry_if_exception_type((requests.exceptions.RequestException, ValueError)),
        before_sleep=lambda retry_state: logger.info(f"é‡è¯•åŸºé‡‘ {retry_state.args[0]}ï¼Œç¬¬ {retry_state.attempt_number} æ¬¡")
    )
    def _fetch_fund_data(self, fund_code, latest_local_date=None):
        """
        ä»ç½‘ç»œè·å–åŸºé‡‘æ•°æ®ï¼Œå®ç°çœŸæ­£çš„å¢é‡æ›´æ–°ã€‚
        å¦‚æœ latest_local_date ä¸ä¸ºç©ºï¼Œåˆ™åªè·å–å…¶ä¹‹åçš„æ•°æ®ã€‚
        """
        all_new_data = []
        page_index = 1
        has_new_data = False
        
        while True:
            url = f"http://fundf10.eastmoney.com/F10DataApi.aspx?type=lsjz&code={fund_code}&page={page_index}&per=20"
            logger.info("æ­£åœ¨è·å–åŸºé‡‘ %s çš„ç¬¬ %d é¡µæ•°æ®...", fund_code, page_index)
            
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                response.raise_for_status()
                
                content_match = re.search(r'content:"(.*?)"', response.text, re.S)
                pages_match = re.search(r'pages:(\d+)', response.text)
                
                if not content_match or not pages_match:
                    logger.error("åŸºé‡‘ %s APIè¿”å›å†…å®¹æ ¼å¼ä¸æ­£ç¡®ï¼Œå¯èƒ½å·²æ— æ•°æ®æˆ–æ¥å£å˜æ›´", fund_code)
                    break

                raw_content_html = content_match.group(1).replace('\\"', '"')
                total_pages = int(pages_match.group(1))
                
                tables = pd.read_html(StringIO(raw_content_html))
                
                if not tables:
                    logger.warning("åŸºé‡‘ %s åœ¨ç¬¬ %d é¡µæœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼ï¼Œçˆ¬å–ç»“æŸ", fund_code, page_index)
                    break
                
                df_page = tables[0]
                df_page.columns = ['date', 'net_value', 'cumulative_net_value', 'daily_growth_rate', 'purchase_status', 'redemption_status', 'dividend']
                df_page = df_page[['date', 'net_value']].copy()
                df_page['date'] = pd.to_datetime(df_page['date'], errors='coerce')
                df_page['net_value'] = pd.to_numeric(df_page['net_value'], errors='coerce')
                df_page = df_page.dropna(subset=['date', 'net_value'])
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦å·²è·å–åˆ°æœ¬åœ°æœ€æ–°æ•°æ®ä¹‹å‰çš„æ•°æ®
                if latest_local_date:
                    new_df_page = df_page[df_page['date'].dt.date > latest_local_date]
                    if new_df_page.empty:
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”ä¹‹å‰å·²ç»å‘ç°è¿‡æ–°æ•°æ®ï¼Œåˆ™åœæ­¢çˆ¬å–
                        if has_new_data:
                            logger.info("åŸºé‡‘ %s å·²è·å–æ‰€æœ‰æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", fund_code)
                            break
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æ˜¯ç¬¬ä¸€é¡µï¼Œåˆ™è¯´æ˜æ²¡æœ‰æ–°æ•°æ®
                        elif page_index == 1:
                            logger.info("åŸºé‡‘ %s æ— æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", fund_code)
                            break
                    else:
                        has_new_data = True
                        all_new_data.append(new_df_page)
                        logger.info("ç¬¬ %d é¡µ: å‘ç° %d è¡Œæ–°æ•°æ®", page_index, len(new_df_page))
                else:
                    # å¦‚æœæ˜¯é¦–æ¬¡ä¸‹è½½ï¼Œåˆ™è·å–æ‰€æœ‰æ•°æ®
                    all_new_data.append(df_page)

                logger.info("åŸºé‡‘ %s æ€»é¡µæ•°: %d, å½“å‰é¡µ: %d, å½“å‰é¡µè¡Œæ•°: %d", fund_code, total_pages, page_index, len(df_page))
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œä¸”å½“å‰é¡µæ•°æ®æ¯”æœ€æ–°æ•°æ®æ—¥æœŸæ—©ï¼Œåˆ™ç»“æŸå¾ªç¯
                if latest_local_date and (df_page['date'].dt.date <= latest_local_date).any():
                    logger.info("åŸºé‡‘ %s å·²è¿½æº¯åˆ°æœ¬åœ°æ•°æ®ï¼Œå¢é‡çˆ¬å–ç»“æŸã€‚", fund_code)
                    break

                if page_index >= total_pages:
                    logger.info("åŸºé‡‘ %s å·²è·å–æ‰€æœ‰å†å²æ•°æ®ï¼Œå…± %d é¡µï¼Œçˆ¬å–ç»“æŸ", fund_code, total_pages)
                    break
                
                page_index += 1
                time_module.sleep(random.uniform(1, 2))  # å»¶é•¿sleepåˆ°1-2ç§’ï¼Œå‡å°‘é™é€Ÿé£é™©
                
            except requests.exceptions.RequestException as e:
                logger.error("åŸºé‡‘ %s APIè¯·æ±‚å¤±è´¥: %s", fund_code, str(e))
                raise
            except Exception as e:
                logger.error("åŸºé‡‘ %s APIæ•°æ®è§£æå¤±è´¥: %s", fund_code, str(e))
                raise

        # åˆå¹¶æ–°æ•°æ®å¹¶è¿”å›
        if all_new_data:
            new_combined_df = pd.concat(all_new_data, ignore_index=True)
            return new_combined_df[['date', 'net_value']]
        else:
            return pd.DataFrame()

    def _fetch_index_data(self, latest_local_date=None):
        """
        ä»ç½‘ç»œè·å–å¤§ç›˜æŒ‡æ•°æ•°æ®ï¼ˆæ²ªæ·±300ï¼‰ï¼Œå®ç°å¢é‡æ›´æ–°ã€‚
        """
        all_new_data = []
        page_index = 1
        has_new_data = False
        
        while True:
            url = f"http://fundf10.eastmoney.com/F10DataApi.aspx?type=lsjz&code={self.index_code}&page={page_index}&per=20"
            logger.info("æ­£åœ¨è·å–å¤§ç›˜æŒ‡æ•° %s çš„ç¬¬ %d é¡µæ•°æ®...", self.index_code, page_index)
            
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                response.raise_for_status()
                
                content_match = re.search(r'content:"(.*?)"', response.text, re.S)
                pages_match = re.search(r'pages:(\d+)', response.text)
                
                if not content_match or not pages_match:
                    logger.error("å¤§ç›˜æŒ‡æ•° %s APIè¿”å›å†…å®¹æ ¼å¼ä¸æ­£ç¡®ï¼Œå¯èƒ½å·²æ— æ•°æ®æˆ–æ¥å£å˜æ›´", self.index_code)
                    break

                raw_content_html = content_match.group(1).replace('\\"', '"')
                total_pages = int(pages_match.group(1))
                
                tables = pd.read_html(StringIO(raw_content_html))
                
                if not tables:
                    logger.warning("å¤§ç›˜æŒ‡æ•° %s åœ¨ç¬¬ %d é¡µæœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼ï¼Œçˆ¬å–ç»“æŸ", self.index_code, page_index)
                    break
                
                df_page = tables[0]
                df_page.columns = ['date', 'net_value', 'cumulative_net_value', 'daily_growth_rate', 'purchase_status', 'redemption_status', 'dividend']
                df_page = df_page[['date', 'net_value']].copy()
                df_page['date'] = pd.to_datetime(df_page['date'], errors='coerce')
                df_page['net_value'] = pd.to_numeric(df_page['net_value'], errors='coerce')
                df_page = df_page.dropna(subset=['date', 'net_value'])
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦å·²è·å–åˆ°æœ¬åœ°æœ€æ–°æ•°æ®ä¹‹å‰çš„æ•°æ®
                if latest_local_date:
                    new_df_page = df_page[df_page['date'].dt.date > latest_local_date]
                    if new_df_page.empty:
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”ä¹‹å‰å·²ç»å‘ç°è¿‡æ–°æ•°æ®ï¼Œåˆ™åœæ­¢çˆ¬å–
                        if has_new_data:
                            logger.info("å¤§ç›˜æŒ‡æ•° %s å·²è·å–æ‰€æœ‰æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", self.index_code)
                            break
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æ˜¯ç¬¬ä¸€é¡µï¼Œåˆ™è¯´æ˜æ²¡æœ‰æ–°æ•°æ®
                        elif page_index == 1:
                            logger.info("å¤§ç›˜æŒ‡æ•° %s æ— æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", self.index_code)
                            break
                    else:
                        has_new_data = True
                        all_new_data.append(new_df_page)
                        logger.info("ç¬¬ %d é¡µ: å‘ç° %d è¡Œæ–°æ•°æ®", page_index, len(new_df_page))
                else:
                    # å¦‚æœæ˜¯é¦–æ¬¡ä¸‹è½½ï¼Œåˆ™è·å–æ‰€æœ‰æ•°æ®
                    all_new_data.append(df_page)

                logger.info("å¤§ç›˜æŒ‡æ•° %s æ€»é¡µæ•°: %d, å½“å‰é¡µ: %d, å½“å‰é¡µè¡Œæ•°: %d", self.index_code, total_pages, page_index, len(df_page))
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œä¸”å½“å‰é¡µæ•°æ®æ¯”æœ€æ–°æ•°æ®æ—¥æœŸæ—©ï¼Œåˆ™ç»“æŸå¾ªç¯
                if latest_local_date and (df_page['date'].dt.date <= latest_local_date).any():
                    logger.info("å¤§ç›˜æŒ‡æ•° %s å·²è¿½æº¯åˆ°æœ¬åœ°æ•°æ®ï¼Œå¢é‡çˆ¬å–ç»“æŸã€‚", self.index_code)
                    break

                if page_index >= total_pages:
                    logger.info("å¤§ç›˜æŒ‡æ•° %s å·²è·å–æ‰€æœ‰å†å²æ•°æ®ï¼Œå…± %d é¡µï¼Œçˆ¬å–ç»“æŸ", self.index_code, total_pages)
                    break
                
                page_index += 1
                time_module.sleep(random.uniform(1, 2))  # å»¶é•¿sleepåˆ°1-2ç§’ï¼Œå‡å°‘é™é€Ÿé£é™©
                
            except requests.exceptions.RequestException as e:
                logger.error("å¤§ç›˜æŒ‡æ•° %s APIè¯·æ±‚å¤±è´¥: %s", self.index_code, str(e))
                raise
            except Exception as e:
                logger.error("å¤§ç›˜æŒ‡æ•° %s APIæ•°æ®è§£æå¤±è´¥: %s", self.index_code, str(e))
                raise

        # åˆå¹¶æ–°æ•°æ®å¹¶è¿”å›
        if all_new_data:
            new_combined_df = pd.concat(all_new_data, ignore_index=True)
            return new_combined_df[['date', 'net_value']]
        else:
            return pd.DataFrame()

    def _calculate_indicators(self, df):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¹¶ç”Ÿæˆç»“æœå­—å…¸"""
        if df is None or df.empty or len(df) < 26:
            return None

        df = df.sort_values(by='date', ascending=True)
        
        # MACD
        exp12 = df['net_value'].ewm(span=12, adjust=False).mean()
        exp26 = df['net_value'].ewm(span=26, adjust=False).mean()
        df['macd'] = exp12 - exp26
        df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()

        # å¸ƒæ—å¸¦
        window = 20
        df['bb_mid'] = df['net_value'].rolling(window=window, min_periods=1).mean()
        df['bb_std'] = df['net_value'].rolling(window=window, min_periods=1).std()
        df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * 2)
        df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * 2)
        
        # RSI
        delta = df['net_value'].diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=14, min_periods=1).mean()
        avg_loss = loss.rolling(window=14, min_periods=1).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.nan)
        df['rsi'] = 100 - (100 / (1 + rs))

        # MA50
        df['ma50'] = df['net_value'].rolling(window=min(50, len(df)), min_periods=1).mean()
        df['ma_ratio'] = df['net_value'] / df['ma50']

        return df

    def _get_latest_signals(self, fund_code, df):
        """æ ¹æ®æœ€æ–°æ•°æ®è®¡ç®—ä¿¡å·"""
        try:
            processed_df = self._calculate_indicators(df)
            if processed_df is None:
                logger.warning("åŸºé‡‘ %s æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®¡ç®—", fund_code)
                return {
                    'fund_code': fund_code, 'latest_net_value': "æ•°æ®è·å–å¤±è´¥", 'rsi': np.nan, 'ma_ratio': np.nan,
                    'macd_diff': np.nan, 'bb_upper': np.nan, 'bb_lower': np.nan, 'bb_position': 'N/A', 'advice': "è§‚å¯Ÿ", 'action_signal': 'N/A'
                }
            
            latest_data = processed_df.iloc[-1]
            latest_net_value = latest_data['net_value']
            latest_rsi = latest_data['rsi']
            latest_ma50_ratio = latest_data['ma_ratio']
            latest_macd_diff = latest_data['macd'] - latest_data['signal']
            latest_bb_upper = latest_data['bb_upper']
            latest_bb_lower = latest_data['bb_lower']

            advice = "è§‚å¯Ÿ"
            if (not np.isnan(latest_rsi) and latest_rsi > 70) or \
               (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
               (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2):
                advice = "ç­‰å¾…å›è°ƒ"
            elif (not np.isnan(latest_rsi) and latest_rsi < 30) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.8):
                advice = "å¯åˆ†æ‰¹ä¹°å…¥"
            elif (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                advice = "å¯åˆ†æ‰¹ä¹°å…¥"
            elif (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 1) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff < 0):
                advice = "ç­‰å¾…å›è°ƒ"

            action_signal = "æŒæœ‰/è§‚å¯Ÿ"
            if not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.95:
                action_signal = "å¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 70) and \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff < 0):
                action_signal = "å¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 65) or \
                 (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2):
                action_signal = "å¼±å–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi < 35) and \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.9) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                action_signal = "å¼ºä¹°å…¥"
            elif (not np.isnan(latest_rsi) and latest_rsi < 45) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 1):
                action_signal = "å¼±ä¹°å…¥"

            # è®¡ç®—å¸ƒæ—å¸¦ä½ç½®
            bb_position = "ä¸­è½¨"
            if not np.isnan(latest_net_value) and not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper:
                bb_position = "ä¸Šè½¨ä¸Šæ–¹"
            elif not np.isnan(latest_net_value) and not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower:
                bb_position = "ä¸‹è½¨ä¸‹æ–¹"

            return {
                'fund_code': fund_code,
                'latest_net_value': latest_net_value,
                'rsi': latest_rsi,
                'ma_ratio': latest_ma50_ratio,
                'macd_diff': latest_macd_diff,
                'bb_upper': latest_bb_upper,
                'bb_lower': latest_bb_lower,
                'bb_position': bb_position,
                'advice': advice,
                'action_signal': action_signal
            }
        except Exception as e:
            logger.error("å¤„ç†åŸºé‡‘ %s æ—¶å‘ç”Ÿå¼‚å¸¸: %s", fund_code, str(e))
            return {
                'fund_code': fund_code,
                'latest_net_value': "æ•°æ®è·å–å¤±è´¥",
                'rsi': np.nan,
                'ma_ratio': np.nan,
                'macd_diff': np.nan,
                'bb_upper': np.nan,
                'bb_lower': np.nan,
                'bb_position': 'N/A',
                'advice': "è§‚å¯Ÿ",
                'action_signal': 'N/A'
            }

    def _analyze_index(self):
        """åˆ†æå¤§ç›˜æŒ‡æ•°ï¼Œè®¡ç®—æŠ€æœ¯æŒ‡æ ‡å’Œä¿¡å·"""
        logger.info("å¼€å§‹åˆ†æå¤§ç›˜æŒ‡æ•° %s...", self.index_code)
        local_df = self._read_local_data(self.index_code)
        latest_local_date = local_df['date'].max().date() if not local_df.empty else None

        new_df = self._fetch_index_data(latest_local_date)
        
        if not new_df.empty:
            df_final = pd.concat([local_df, new_df]).drop_duplicates(subset=['date'], keep='last').sort_values(by='date', ascending=True)
            self._save_to_local_file(self.index_code, df_final)
            self.index_df = df_final
            result = self._get_latest_signals(self.index_code, df_final.tail(100))
            self.index_data = result
            logger.info("å¤§ç›˜æŒ‡æ•° %s åˆ†æå®Œæˆ", self.index_code)
        elif not local_df.empty:
            # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æœ¬åœ°æœ‰æ•°æ®ï¼Œåˆ™ä½¿ç”¨æœ¬åœ°æ•°æ®è®¡ç®—ä¿¡å·
            logger.info("å¤§ç›˜æŒ‡æ•° %s æ— æ–°æ•°æ®ï¼Œä½¿ç”¨æœ¬åœ°å†å²æ•°æ®è¿›è¡Œåˆ†æ", self.index_code)
            self.index_df = local_df
            result = self._get_latest_signals(self.index_code, local_df.tail(100))
            self.index_data = result
            logger.info("å¤§ç›˜æŒ‡æ•° %s åˆ†æå®Œæˆ", self.index_code)
        else:
            # å¦‚æœæ—¢æ²¡æœ‰æ–°æ•°æ®ï¼Œæœ¬åœ°åˆæ²¡æœ‰æ•°æ®ï¼Œåˆ™è¿”å›å¤±è´¥
            logger.error("å¤§ç›˜æŒ‡æ•° %s æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œä¸”æœ¬åœ°æ— ç¼“å­˜", self.index_code)
            self.index_data = {
                'fund_code': self.index_code,
                'latest_net_value': "æ•°æ®è·å–å¤±è´¥",
                'rsi': np.nan,
                'ma_ratio': np.nan,
                'macd_diff': np.nan,
                'bb_upper': np.nan,
                'bb_lower': np.nan,
                'bb_position': 'N/A',
                'advice': "è§‚å¯Ÿ",
                'action_signal': 'N/A'
            }

    def get_fund_data(self):
        """ä¸»æ§å‡½æ•°ï¼šä¼˜å…ˆä»æœ¬åœ°åŠ è½½ï¼Œä»…åœ¨æ•°æ®éæœ€æ–°æˆ–ä¸å®Œæ•´æ—¶ä¸‹è½½"""
        # æ­¥éª¤1: è§£ææ¨èåŸºé‡‘ä»£ç 
        self._parse_report()
        if not self.fund_codes:
            logger.error("æ²¡æœ‰æå–åˆ°ä»»ä½•åŸºé‡‘ä»£ç ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
            return

        # æ­¥éª¤2: é¢„åŠ è½½æœ¬åœ°æ•°æ®å¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸‹è½½
        logger.info("å¼€å§‹é¢„åŠ è½½æœ¬åœ°ç¼“å­˜æ•°æ®...")
        fund_codes_to_fetch = []
        expected_latest_date = self._get_expected_latest_date()
        min_data_points = 26  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡

        for fund_code in self.fund_codes:
            local_df = self._read_local_data(fund_code)
            
            if not local_df.empty:
                latest_local_date = local_df['date'].max().date()
                data_points = len(local_df)
                
                # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ€æ–°ä¸”å®Œæ•´
                if latest_local_date >= expected_latest_date and data_points >= min_data_points:
                    logger.info("åŸºé‡‘ %s çš„æœ¬åœ°æ•°æ®å·²æ˜¯æœ€æ–° (%s, æœŸæœ›: %s) ä¸”æ•°æ®é‡è¶³å¤Ÿ (%d è¡Œ)ï¼Œç›´æ¥åŠ è½½ã€‚",
                                 fund_code, latest_local_date, expected_latest_date, data_points)
                    self.fund_data[fund_code] = self._get_latest_signals(fund_code, local_df.tail(100))
                    continue
                else:
                    if latest_local_date < expected_latest_date:
                        logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®å·²è¿‡æ—¶ï¼ˆæœ€æ–°æ—¥æœŸä¸º %sï¼ŒæœŸæœ› %sï¼‰ï¼Œéœ€è¦ä»ç½‘ç»œè·å–æ–°æ•°æ®ã€‚",
                                     fund_code, latest_local_date, expected_latest_date)
                    if data_points < min_data_points:
                        logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®é‡ä¸è¶³ï¼ˆä»… %d è¡Œï¼Œéœ€è‡³å°‘ %d è¡Œï¼‰ï¼Œéœ€è¦ä»ç½‘ç»œè·å–ã€‚",
                                     fund_code, data_points, min_data_points)
            else:
                logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®ä¸å­˜åœ¨ï¼Œéœ€è¦ä»ç½‘ç»œè·å–ã€‚", fund_code)
            
            fund_codes_to_fetch.append(fund_code)

        # æ­¥éª¤3: å¤šçº¿ç¨‹ç½‘ç»œä¸‹è½½å’Œå¤„ç†
        if fund_codes_to_fetch:
            logger.info("å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹è·å– %d ä¸ªåŸºé‡‘çš„æ–°æ•°æ®...", len(fund_codes_to_fetch))
            with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                future_to_code = {executor.submit(self._process_single_fund, code): code for code in fund_codes_to_fetch}
                for future in concurrent.futures.as_completed(future_to_code):
                    fund_code = future_to_code[future]
                    try:
                        result = future.result()
                        if result:
                            self.fund_data[fund_code] = result
                    except Exception as e:
                        logger.error("å¤„ç†åŸºé‡‘ %s æ•°æ®æ—¶å‡ºé”™: %s", fund_code, str(e))
                        self.fund_data[fund_code] = {
                            'fund_code': fund_code, 'latest_net_value': "æ•°æ®è·å–å¤±è´¥", 'rsi': np.nan,
                            'ma_ratio': np.nan, 'macd_diff': np.nan, 'bb_upper': np.nan, 'bb_lower': np.nan, 
                            'bb_position': 'N/A', 'advice': "è§‚å¯Ÿ", 'action_signal': 'N/A'
                        }
        else:
            logger.info("æ‰€æœ‰åŸºé‡‘æ•°æ®å‡æ¥è‡ªæœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€ç½‘ç»œä¸‹è½½ã€‚")
        
        if len(self.fund_data) > 0:
            logger.info("æ‰€æœ‰åŸºé‡‘æ•°æ®å¤„ç†å®Œæˆã€‚")
        else:
            logger.error("æ‰€æœ‰åŸºé‡‘æ•°æ®å‡è·å–å¤±è´¥ã€‚")

        # æ–°å¢ï¼šåˆ†æå¤§ç›˜æŒ‡æ•°
        self._analyze_index()

    def _process_single_fund(self, fund_code):
        """å¤„ç†å•ä¸ªåŸºé‡‘æ•°æ®ï¼šè¯»å–æœ¬åœ°ï¼Œä¸‹è½½å¢é‡ï¼Œåˆå¹¶ï¼Œä¿å­˜ï¼Œå¹¶è®¡ç®—ä¿¡å·"""
        local_df = self._read_local_data(fund_code)
        latest_local_date = local_df['date'].max().date() if not local_df.empty else None

        new_df = self._fetch_fund_data(fund_code, latest_local_date)
        
        if not new_df.empty:
            df_final = pd.concat([local_df, new_df]).drop_duplicates(subset=['date'], keep='last').sort_values(by='date', ascending=True)
            self._save_to_local_file(fund_code, df_final)
            return self._get_latest_signals(fund_code, df_final.tail(100))
        elif not local_df.empty:
            # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æœ¬åœ°æœ‰æ•°æ®ï¼Œåˆ™ä½¿ç”¨æœ¬åœ°æ•°æ®è®¡ç®—ä¿¡å·
            logger.info("åŸºé‡‘ %s æ— æ–°æ•°æ®ï¼Œä½¿ç”¨æœ¬åœ°å†å²æ•°æ®è¿›è¡Œåˆ†æ", fund_code)
            return self._get_latest_signals(fund_code, local_df.tail(100))
        else:
            # å¦‚æœæ—¢æ²¡æœ‰æ–°æ•°æ®ï¼Œæœ¬åœ°åˆæ²¡æœ‰æ•°æ®ï¼Œåˆ™è¿”å›å¤±è´¥
            logger.error("åŸºé‡‘ %s æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œä¸”æœ¬åœ°æ— ç¼“å­˜", fund_code)
            return None
    
    def _backtest_strategy(self, fund_code, df):
        """å†å²å›æµ‹ç­–ç•¥æ€§èƒ½"""
        if df is None or df.empty or len(df) < 100:
            logger.warning("åŸºé‡‘ %s æ•°æ®ä¸è¶³ï¼Œæ— æ³•å›æµ‹", fund_code)
            return {"cum_return": np.nan, "max_drawdown": np.nan, "sharpe_ratio": np.nan, "win_rate": np.nan, "cagr": np.nan, "total_trades": 0}

        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        df = self._calculate_indicators(df)
        df = df.dropna()
        # å…³é”®ä¿®å¤ï¼šé‡ç½®ç´¢å¼•ä»¥ç¡®ä¿åç»­å¾ªç¯çš„.ilocæ­£å¸¸å·¥ä½œ
        df.reset_index(drop=True, inplace=True)

        # å¢åŠ ä¸€ä¸ªæ£€æŸ¥ï¼Œç¡®ä¿dropnaåä»æœ‰è¶³å¤Ÿçš„æ•°æ®
        if df.empty or len(df) < 2:
            logger.warning("åŸºé‡‘ %s è®¡ç®—æŒ‡æ ‡åæ•°æ®ä¸è¶³ï¼Œæ— æ³•å›æµ‹", fund_code)
            return {"cum_return": np.nan, "max_drawdown": np.nan, "sharpe_ratio": np.nan, "win_rate": np.nan, "cagr": np.nan, "total_trades": 0}

        # æ¨¡æ‹Ÿäº¤æ˜“
        position = 0
        buy_price = 0
        trades = []
        equity = [1.0] * len(df)
        
        for i in range(1, len(df)):
            latest_data = df.iloc[i]
            latest_net_value = latest_data['net_value']
            
            # æœ€å¤§å›æ’¤è®¡ç®—
            prev_net_value = df['net_value'].iloc[i-1]
            if prev_net_value != 0:
                equity[i] = equity[i-1] * (1 + (latest_net_value - prev_net_value) / prev_net_value)
            else:
                equity[i] = equity[i-1]

            # æ­¢æŸé€»è¾‘
            if position == 1 and (latest_net_value / buy_price) < 0.90:  # æ­¢æŸ10%
                sell_price = latest_net_value
                ret = (sell_price - buy_price) / buy_price
                trades.append({'buy_date': df.iloc[i-1]['date'], 'sell_date': df.iloc[i]['date'], 'return': ret, 'type': 'stop_loss'})
                position = 0
                buy_price = 0
                continue # ç»§ç»­ä¸‹ä¸€å¤©

            # äº¤æ˜“ä¿¡å·é€»è¾‘
            latest_rsi = latest_data['rsi']
            latest_ma_ratio = latest_data['ma_ratio']
            latest_macd_diff = latest_data['macd'] - latest_data['signal']
            latest_bb_upper = latest_data['bb_upper']
            latest_bb_lower = latest_data['bb_lower']

            action_signal = "æŒæœ‰/è§‚å¯Ÿ"
            if not np.isnan(latest_ma_ratio) and latest_ma_ratio < 0.95:
                action_signal = "å¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 70) and \
                 (not np.isnan(latest_ma_ratio) and latest_ma_ratio > 1.2) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff < 0):
                action_signal = "å¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 65) or \
                 (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
                 (not np.isnan(latest_ma_ratio) and latest_ma_ratio > 1.2):
                action_signal = "å¼±å–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi < 35) and \
                 (not np.isnan(latest_ma_ratio) and latest_ma_ratio < 0.9) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                action_signal = "å¼ºä¹°å…¥"
            elif (not np.isnan(latest_rsi) and latest_rsi < 45) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma_ratio) and latest_ma_ratio < 1):
                action_signal = "å¼±ä¹°å…¥"
            
            # æ¨¡æ‹Ÿäº¤æ˜“
            if action_signal in ["å¼ºä¹°å…¥", "å¼±ä¹°å…¥"] and position == 0:
                position = 1
                buy_price = latest_net_value
                # ä¿®å¤: ä½¿ç”¨ .iloc è¿›è¡ŒåŸºäºä½ç½®çš„ç´¢å¼•
                trades.append({'buy_date': df.iloc[i]['date'], 'buy_price': buy_price})
            elif action_signal in ["å¼ºå–å‡º/è§„é¿", "å¼±å–å‡º/è§„é¿"] and position == 1:
                sell_price = latest_net_value
                ret = (sell_price - buy_price) / buy_price
                trades[-1]['sell_date'] = df.iloc[i]['date']
                trades[-1]['sell_price'] = sell_price
                trades[-1]['return'] = ret
                position = 0

        # å¦‚æœæœ€åè¿˜æŒæœ‰ï¼Œåˆ™ä»¥æœ€åä¸€å¤©å‡€å€¼å–å‡º
        if position == 1:
            sell_price = df.iloc[-1]['net_value']
            ret = (sell_price - buy_price) / buy_price
            trades[-1]['sell_date'] = df.iloc[-1]['date']
            trades[-1]['sell_price'] = sell_price
            trades[-1]['return'] = ret

        # è®¡ç®—å›æµ‹æŒ‡æ ‡
        if trades:
            returns = [trade['return'] for trade in trades if 'return' in trade]
            cum_return = np.prod([1 + r for r in returns]) - 1 if returns else 0
            win_rate = len([r for r in returns if r > 0]) / len(returns) if returns else 0
            total_trades = len(trades)
        else:
            cum_return = 0
            win_rate = 0
            total_trades = 0
        
        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
        start_date = df['date'].iloc[0]
        end_date = df['date'].iloc[-1]
        years = (end_date - start_date).days / 365.25
        cagr = (1 + cum_return) ** (1/years) - 1 if years > 0 else 0

        # è®¡ç®—æœ€å¤§å›æ’¤
        equity_series = pd.Series(equity)
        roll_max = equity_series.cummax()
        drawdown = equity_series / roll_max - 1
        max_drawdown = drawdown.min()

        # è®¡ç®—å¤æ™®æ¯”ç‡
        daily_returns = pd.Series(equity).pct_change().dropna()
        sharpe_ratio = np.mean(daily_returns) / np.std(daily_returns) * np.sqrt(252) if len(daily_returns) > 1 and np.std(daily_returns) > 0 else np.nan

        logger.info("åŸºé‡‘ %s å›æµ‹ç»“æœ: ç´¯è®¡å›æŠ¥=%.2f, æœ€å¤§å›æ’¤=%.2f, å¤æ™®æ¯”ç‡=%.2f, èƒœç‡=%.2f, å¹´åŒ–æ”¶ç›Šç‡=%.2f, äº¤æ˜“æ¬¡æ•°=%d", 
                      fund_code, cum_return, max_drawdown, sharpe_ratio if not np.isnan(sharpe_ratio) else -1, win_rate, cagr, total_trades)
        
        return {
            "cum_return": cum_return,
            "max_drawdown": max_drawdown,
            "sharpe_ratio": sharpe_ratio,
            "win_rate": win_rate,
            "cagr": cagr,
            "total_trades": total_trades
        }

    def generate_report(self):
        """ç”Ÿæˆå¸‚åœºæƒ…ç»ªä¸æŠ€æœ¯æŒ‡æ ‡ç›‘æ§æŠ¥å‘Š"""
        logger.info("æ­£åœ¨ç”Ÿæˆå¸‚åœºç›‘æ§æŠ¥å‘Š...")
        report_df_list = []
        for fund_code in self.fund_codes:
            data = self.fund_data.get(fund_code)
            if data is not None:
                latest_net_value_str = f"{data['latest_net_value']:.4f}" if isinstance(data['latest_net_value'], (float, int)) else str(data['latest_net_value'])
                rsi_str = f"{data['rsi']:.2f}" if isinstance(data['rsi'], (float, int)) and not np.isnan(data['rsi']) else "N/A"
                ma_ratio_str = f"{data['ma_ratio']:.2f}" if isinstance(data['ma_ratio'], (float, int)) and not np.isnan(data['ma_ratio']) else "N/A"
                
                macd_signal = "N/A"
                if isinstance(data['macd_diff'], (float, int)) and not np.isnan(data['macd_diff']):
                    macd_signal = "é‡‘å‰" if data['macd_diff'] > 0 else "æ­»å‰"
                
                # ä½¿ç”¨è®¡ç®—å¥½çš„bb_position
                bollinger_pos = data.get('bb_position', "ä¸­è½¨")
                
                report_df_list.append({
                    "åŸºé‡‘ä»£ç ": fund_code,
                    "æœ€æ–°å‡€å€¼": latest_net_value_str,
                    "RSI": rsi_str,
                    "å‡€å€¼/MA50": ma_ratio_str,
                    "MACDä¿¡å·": macd_signal,
                    "å¸ƒæ—å¸¦ä½ç½®": bollinger_pos,
                    "æŠ•èµ„å»ºè®®": data['advice'],
                    "è¡ŒåŠ¨ä¿¡å·": data['action_signal']
                })
            else:
                report_df_list.append({
                    "åŸºé‡‘ä»£ç ": fund_code,
                    "æœ€æ–°å‡€å€¼": "æ•°æ®è·å–å¤±è´¥",
                    "RSI": "N/A",
                    "å‡€å€¼/MA50": "N/A",
                    "MACDä¿¡å·": "N/A",
                    "å¸ƒæ—å¸¦ä½ç½®": "N/A",
                    "æŠ•èµ„å»ºè®®": "è§‚å¯Ÿ",
                    "è¡ŒåŠ¨ä¿¡å·": "N/A"
                })

        report_df = pd.DataFrame(report_df_list)

        # å®šä¹‰æ’åºä¼˜å…ˆçº§
        order_map_action = {
            "å¼ºä¹°å…¥": 1,
            "å¼±ä¹°å…¥": 2,
            "æŒæœ‰/è§‚å¯Ÿ": 3,
            "å¼±å–å‡º/è§„é¿": 4,
            "å¼ºå–å‡º/è§„é¿": 5,
            "N/A": 6
        }
        order_map_advice = {
            "å¯åˆ†æ‰¹ä¹°å…¥": 1,
            "è§‚å¯Ÿ": 2,
            "ç­‰å¾…å›è°ƒ": 3,
            "N/A": 4
        }
        
        report_df['sort_order_action'] = report_df['è¡ŒåŠ¨ä¿¡å·'].map(order_map_action)
        report_df['sort_order_advice'] = report_df['æŠ•èµ„å»ºè®®'].map(order_map_advice)
        
        # å°† NaN æ›¿æ¢ä¸º N/A å¹¶å¯¹å‡€å€¼ç­‰æ•°æ®ç±»å‹è¿›è¡Œå¤„ç†
        report_df['æœ€æ–°å‡€å€¼'] = pd.to_numeric(report_df['æœ€æ–°å‡€å€¼'], errors='coerce')
        report_df['RSI'] = pd.to_numeric(report_df['RSI'], errors='coerce')
        report_df['å‡€å€¼/MA50'] = pd.to_numeric(report_df['å‡€å€¼/MA50'], errors='coerce')

        # æŒ‰ç…§æ‚¨çš„æ–°æ’åºè§„åˆ™è¿›è¡Œæ’åº
        report_df = report_df.sort_values(
            by=['sort_order_action', 'sort_order_advice', 'RSI'],
            ascending=[True, True, True] # ä¼˜å…ˆæŒ‰è¡ŒåŠ¨ä¿¡å·ã€å…¶æ¬¡æŒ‰æŠ•èµ„å»ºè®®ã€æœ€åæŒ‰RSIä»ä½åˆ°é«˜æ’åº
        ).drop(columns=['sort_order_action', 'sort_order_advice'])

        # å°†æµ®ç‚¹æ•°æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿Markdownè¾“å‡º
        report_df['æœ€æ–°å‡€å€¼'] = report_df['æœ€æ–°å‡€å€¼'].apply(lambda x: f"{x:.4f}" if not pd.isna(x) else "N/A")
        report_df['RSI'] = report_df['RSI'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
        report_df['å‡€å€¼/MA50'] = report_df['å‡€å€¼/MA50'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")

        # å°†ä¸Šè¿°æ’åºåçš„ DataFrame è½¬æ¢ä¸º Markdown
        markdown_table = report_df.to_markdown(index=False)
        
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write(f"# å¸‚åœºæƒ…ç»ªä¸æŠ€æœ¯æŒ‡æ ‡ç›‘æ§æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # æ–°å¢ï¼šå¤§ç›˜æŒ‡æ•°åˆ†æéƒ¨åˆ†
            f.write(f"## å¤§ç›˜æŒ‡æ•°åˆ†æ (æ²ªæ·±300)\n")
            f.write("æ­¤éƒ¨åˆ†æä¾›å¤§ç›˜æ•´ä½“å¸‚åœºæƒ…ç»ªå‚è€ƒï¼Œç”¨äºè¾…åŠ©åŸºé‡‘æŠ•èµ„å†³ç­–ã€‚\n\n")
            index_latest_net_value_str = f"{self.index_data['latest_net_value']:.2f}" if isinstance(self.index_data['latest_net_value'], (float, int)) else str(self.index_data['latest_net_value'])
            index_rsi_str = f"{self.index_data['rsi']:.2f}" if isinstance(self.index_data['rsi'], (float, int)) and not np.isnan(self.index_data['rsi']) else "N/A"
            index_ma_ratio_str = f"{self.index_data['ma_ratio']:.2f}" if isinstance(self.index_data['ma_ratio'], (float, int)) and not np.isnan(self.index_data['ma_ratio']) else "N/A"
            index_macd_signal = "N/A"
            if isinstance(self.index_data['macd_diff'], (float, int)) and not np.isnan(self.index_data['macd_diff']):
                index_macd_signal = "é‡‘å‰" if self.index_data['macd_diff'] > 0 else "æ­»å‰"
            index_bollinger_pos = self.index_data.get('bb_position', "ä¸­è½¨")
            f.write("| æŒ‡æ•°ä»£ç  | æœ€æ–°ç‚¹ä½ | RSI | ç‚¹ä½/MA50 | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | æŠ•èµ„å»ºè®® | è¡ŒåŠ¨ä¿¡å· |\n")
            f.write("|----------|----------|-----|-----------|----------|------------|----------|----------|\n")
            f.write(f"| {self.index_code} | {index_latest_net_value_str} | {index_rsi_str} | {index_ma_ratio_str} | {index_macd_signal} | {index_bollinger_pos} | {self.index_data['advice']} | {self.index_data['action_signal']} |\n\n")

            f.write(f"## æ¨èåŸºé‡‘æŠ€æœ¯æŒ‡æ ‡ (å¤„ç†åŸºé‡‘æ•°: {len(self.fund_codes)})\n")
            f.write("æ­¤è¡¨æ ¼å·²æŒ‰**è¡ŒåŠ¨ä¿¡å·ä¼˜å…ˆçº§**æ’åºï¼Œ'å¼ºä¹°å…¥'åŸºé‡‘å°†æ’åœ¨æœ€å‰é¢ã€‚\n")
            f.write("**æ³¨æ„ï¼š** å½“'è¡ŒåŠ¨ä¿¡å·'å’Œ'æŠ•èµ„å»ºè®®'å†²çªæ—¶ï¼Œè¯·ä»¥**è¡ŒåŠ¨ä¿¡å·**ä¸ºå‡†ï¼Œå…¶æ¡ä»¶æ›´ä¸¥æ ¼ï¼Œæ›´é€‚åˆæœºæ¢°åŒ–å†³ç­–ã€‚\n")
            f.write("**å¤§ç›˜å‚è€ƒï¼š** è¯·ç»“åˆä¸Šæ–¹å¤§ç›˜åˆ†æç»“æœï¼Œè‹¥å¤§ç›˜è¡ŒåŠ¨ä¿¡å·ä¸º'å¼ºå–å‡º/è§„é¿'æˆ–'å¼±å–å‡º/è§„é¿'ï¼Œå»ºè®®é™ä½åŸºé‡‘ä»“ä½ã€‚\n\n")
            f.write(markdown_table)
        
        logger.info("æŠ¥å‘Šç”Ÿæˆå®Œæˆ: %s", self.output_file)

    def _generate_backtest_report(self, backtest_results):
        """å°†å›æµ‹ç»“æœè¾“å‡ºä¸ºMarkdownæŠ¥å‘Š"""
        logger.info("æ­£åœ¨ç”Ÿæˆå›æµ‹æŠ¥å‘Š...")
        if not backtest_results:
            logger.warning("å›æµ‹ç»“æœä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚")
            return

        report_df = pd.DataFrame.from_dict(backtest_results, orient='index')
        report_df = report_df.rename(columns={
            "cum_return": "ç´¯è®¡å›æŠ¥",
            "max_drawdown": "æœ€å¤§å›æ’¤",
            "sharpe_ratio": "å¤æ™®æ¯”ç‡",
            "win_rate": "èƒœç‡",
            "cagr": "å¹´åŒ–æ”¶ç›Šç‡",
            "total_trades": "æ€»äº¤æ˜“æ¬¡æ•°"
        })

        # æ ¼å¼åŒ–æµ®ç‚¹æ•°
        for col in ["ç´¯è®¡å›æŠ¥", "æœ€å¤§å›æ’¤", "å¹´åŒ–æ”¶ç›Šç‡", "èƒœç‡"]:
            report_df[col] = report_df[col].apply(lambda x: f"{x:.2%}" if not pd.isna(x) else "N/A")

        # æ ¼å¼åŒ–å¤æ™®æ¯”ç‡å’Œæ€»äº¤æ˜“æ¬¡æ•°
        report_df['å¤æ™®æ¯”ç‡'] = report_df['å¤æ™®æ¯”ç‡'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
        report_df['æ€»äº¤æ˜“æ¬¡æ•°'] = report_df['æ€»äº¤æ˜“æ¬¡æ•°'].astype(int)

        report_df = report_df.sort_values(by="ç´¯è®¡å›æŠ¥", ascending=False)
        markdown_table = report_df.to_markdown()

        with open(self.backtest_output_file, 'w', encoding='utf-8') as f:
            f.write(f"# å†å²å›æµ‹ç»“æœæŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"æ­¤æŠ¥å‘Šå±•ç¤ºäº†å°†æ‚¨çš„æŠ€æœ¯æŒ‡æ ‡ç­–ç•¥åº”ç”¨äºå†å²æ•°æ®çš„è¡¨ç°ã€‚\n\n")
            f.write("æ­¤è¡¨æ ¼å·²æŒ‰**ç´¯è®¡å›æŠ¥**ä»é«˜åˆ°ä½æ’åºã€‚\n")
            f.write("æ³¨æ„ï¼šæ­¤å›æµ‹åŠ å…¥äº†**10%æ­¢æŸ**é€»è¾‘ï¼Œä»¥æ§åˆ¶å•ç¬”äº¤æ˜“äºæŸã€‚\n\n")
            f.write(markdown_table)
        
        logger.info("å›æµ‹æŠ¥å‘Šç”Ÿæˆå®Œæˆ: %s", self.backtest_output_file)

    def perform_backtest(self):
        """å¯¹æ‰€æœ‰åŸºé‡‘è¿›è¡Œå†å²å›æµ‹ï¼Œå¹¶è¾“å‡ºç»“æœ"""
        backtest_results = {}
        for fund_code in self.fund_codes:
            df = self._read_local_data(fund_code)
            if not df.empty:
                backtest_results[fund_code] = self._backtest_strategy(fund_code, df)
            else:
                logger.warning("åŸºé‡‘ %s æ— å†å²æ•°æ®ï¼Œæ— æ³•å›æµ‹", fund_code)
                backtest_results[fund_code] = {"cum_return": np.nan, "max_drawdown": np.nan, "sharpe_ratio": np.nan, "win_rate": np.nan, "cagr": np.nan, "total_trades": 0}
        
        # å°†ç»“æœä¿å­˜åˆ°CSVæ–‡ä»¶
        backtest_df = pd.DataFrame.from_dict(backtest_results, orient='index')
        backtest_df.to_csv('backtest_results.csv', encoding='utf-8')
        logger.info("å›æµ‹ç»“æœå·²ä¿å­˜åˆ° backtest_results.csv")
        
        # ç”Ÿæˆå›æµ‹æŠ¥å‘Š
        self._generate_backtest_report(backtest_results)

    def _get_portfolio_signals(self, fund_data, max_positions=5):
        """æ ¹æ®è¯„åˆ†è·å–æœ€ä½³ä¹°å…¥æœºä¼šï¼Œå¹¶é™åˆ¶æœ€å¤§æŒä»“æ•°"""
        buy_candidates = []
        for fund_code, data in fund_data.items():
            if data['action_signal'] in ["å¼ºä¹°å…¥", "å¼±ä¹°å…¥"]:
                score = self._calculate_buy_score(data)
                buy_candidates.append({
                    'code': fund_code,
                    'signal': data['action_signal'],
                    'rsi': data['rsi'],
                    'ma_ratio': data['ma_ratio'],
                    'score': score
                })
        
        # æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½æ’åºï¼Œå¹¶é™åˆ¶æ•°é‡
        buy_candidates.sort(key=lambda x: x['score'], reverse=True)
        return buy_candidates[:max_positions]

    def _calculate_buy_score(self, data):
        """æ ¹æ®å¤šä¸ªæŒ‡æ ‡è®¡ç®—ä¹°å…¥è¯„åˆ†ï¼Œç”¨äºç­›é€‰"""
        score = 0
        
        # RSIè¯„åˆ†
        if pd.isna(data['rsi']):
            score += 0
        elif data['rsi'] < 30:
            score += 40
        elif data['rsi'] < 45:
            score += 30
        else:
            score += 10

        # MAæ¯”ç‡è¯„åˆ†
        if pd.isna(data['ma_ratio']):
            score += 0
        elif data['ma_ratio'] < 0.9:
            score += 30
        elif data['ma_ratio'] < 1:
            score += 20
        else:
            score += 5

        # MACDè¯„åˆ†
        if pd.isna(data['macd_diff']):
            score += 0
        elif data['macd_diff'] > 0:
            score += 10
        elif data['macd_diff'] < 0:
            score += 5
        else:
            score += 0

        # å¸ƒæ—å¸¦ä½ç½®è¯„åˆ† - ç›´æ¥ä½¿ç”¨å·²è®¡ç®—çš„ bb_position
        bb_position = data.get('bb_position', "ä¸­è½¨")
        if bb_position == "ä¸‹è½¨ä¸‹æ–¹":
            score += 25
        elif bb_position == "ä¸­è½¨":
            score += 15
        else:
            score += 5
        
        return score

    def generate_portfolio_recommendation(self):
        """ç”ŸæˆæŠ•èµ„ç»„åˆæ¨è"""
        buy_candidates = self._get_portfolio_signals(self.fund_data, max_positions=3)
        
        print("\n" + "="*60)
        print("ğŸ“Š ä»Šæ—¥æŠ•èµ„ç»„åˆæ¨è (æœ€å¤š3æ”¯)")
        print("="*60)
        
        if buy_candidates:
            for i, candidate in enumerate(buy_candidates, 1):
                signal_emoji = "ğŸŸ¢" if candidate['signal'] == "å¼ºä¹°å…¥" else "ğŸŸ¡"
                print(f"{i}. {signal_emoji} {candidate['code']} "
                      f"(è¯„åˆ†: {candidate['score']:.0f}, RSI: {candidate['rsi']:.1f})")
            if buy_candidates:
                suggested_amount = buy_candidates[0]['score'] // 10 * 100
                print(f"\nğŸ’° å»ºè®®åˆ†é…: æ¯æ”¯{ suggested_amount }å…ƒ")
                print(f"ğŸ“ˆ ä»Šæ—¥ä¹°å…¥æœºä¼š: {len(buy_candidates)}/{len(self.fund_codes)}")
        else:
            print("âŒ ä»Šæ—¥æ— ç¬¦åˆæ¡ä»¶çš„ä¹°å…¥æœºä¼šï¼Œå»ºè®®è§‚æœ›")
            print(f"ğŸ“Š æ€»æ‰«æåŸºé‡‘æ•°: {len(self.fund_codes)}")


if __name__ == "__main__":
    try:
        logger.info("è„šæœ¬å¯åŠ¨")
        monitor = MarketMonitor()
        monitor.get_fund_data()
        monitor.generate_report()
        monitor.perform_backtest()
        monitor.generate_portfolio_recommendation()
        logger.info("è„šæœ¬æ‰§è¡Œå®Œæˆ")
    except Exception as e:
        logger.error("è„šæœ¬è¿è¡Œå¤±è´¥: %s", e, exc_info=True)
        raise
