import pandas as pd
import numpy as np
import re
import os
import logging
from datetime import datetime, timedelta, time
import random
from io import StringIO
import requests
import tenacity
import concurrent.futures
import time as time_module

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('market_monitor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å®šä¹‰æœ¬åœ°æ•°æ®å­˜å‚¨ç›®å½•
FUND_DATA_DIR = 'fund_data'
INDEX_DATA_DIR = 'index_data'
if not os.path.exists(FUND_DATA_DIR):
    os.makedirs(FUND_DATA_DIR)
if not os.path.exists(INDEX_DATA_DIR):
    os.makedirs(INDEX_DATA_DIR)

class MarketMonitor:
    def __init__(self, report_file='analysis_report.md', output_file='market_monitor_report.md', backtest_output_file='backtest_report.md'):
        self.report_file = report_file
        self.output_file = output_file
        self.backtest_output_file = backtest_output_file
        self.portfolio_output_file = 'portfolio_recommendation.md'
        self.fund_codes = []
        self.fund_data = {}
        self.index_code = '000300'  # æ²ªæ·±300æŒ‡æ•°ä»£ç 
        self.index_data = {}
        self.index_df = pd.DataFrame()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36'
        }

    def _get_expected_latest_date(self):
        """æ ¹æ®å½“å‰æ—¶é—´ç¡®å®šæœŸæœ›çš„æœ€æ–°æ•°æ®æ—¥æœŸ"""
        now = datetime.now()
        # å‡è®¾å‡€å€¼æ›´æ–°æ—¶é—´ä¸ºæ™šä¸Š21:00
        update_time = time(21, 0)
        if now.time() < update_time:
            # å¦‚æœå½“å‰æ—¶é—´æ—©äº21:00ï¼Œåˆ™æœŸæœ›æœ€æ–°æ—¥æœŸä¸ºæ˜¨å¤©
            expected_date = now.date() - timedelta(days=1)
        else:
            # å¦åˆ™ï¼ŒæœŸæœ›æœ€æ–°æ—¥æœŸä¸ºä»Šå¤©
            expected_date = now.date()
        logger.info("å½“å‰æ—¶é—´: %s, æœŸæœ›æœ€æ–°æ•°æ®æ—¥æœŸ: %s", now.strftime('%Y-%m-%d %H:%M:%S'), expected_date)
        return expected_date

    def _parse_report(self, report_path='analysis_report.md'):
        """ä» analysis_report.md æå–æ¨èåŸºé‡‘ä»£ç """
        logger.info("æ­£åœ¨è§£æ %s è·å–æ¨èåŸºé‡‘ä»£ç ...", report_path)
        if not os.path.exists(report_path):
            logger.error("æŠ¥å‘Šæ–‡ä»¶ %s ä¸å­˜åœ¨", report_path)
            raise FileNotFoundError(f"{report_path} ä¸å­˜åœ¨")
        
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            pattern = re.compile(r'(?:^\| +(\d{6})|### åŸºé‡‘ (\d{6}))', re.M)
            matches = pattern.findall(content)

            extracted_codes = set()
            for match in matches:
                code = match[0] if match[0] else match[1]
                extracted_codes.add(code)
            
            sorted_codes = sorted(list(extracted_codes))
            self.fund_codes = sorted_codes[:1000]
            
            if not self.fund_codes:
                logger.warning("æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆåŸºé‡‘ä»£ç ï¼Œè¯·æ£€æŸ¥ analysis_report.md")
            else:
                logger.info("æå–åˆ° %d ä¸ªåŸºé‡‘ï¼ˆæµ‹è¯•é™åˆ¶å‰1000ä¸ªï¼‰: %s", len(self.fund_codes), self.fund_codes)
            
        except Exception as e:
            logger.error("è§£ææŠ¥å‘Šæ–‡ä»¶å¤±è´¥: %s", e)
            raise

    def _read_local_data(self, fund_code):
        """è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨åˆ™è¿”å›DataFrame"""
        file_path = os.path.join(FUND_DATA_DIR, f"{fund_code}.csv")
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path, parse_dates=['date'])
                if not df.empty and 'date' in df.columns and 'net_value' in df.columns:
                    df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
                    logger.info("æœ¬åœ°å·²å­˜åœ¨åŸºé‡‘ %s æ•°æ®ï¼Œå…± %d è¡Œï¼Œæœ€æ–°æ—¥æœŸä¸º: %s", fund_code, len(df), df['date'].max().date())
                    return df
            except Exception as e:
                logger.warning("è¯»å–æœ¬åœ°æ–‡ä»¶ %s å¤±è´¥: %s", file_path, e)
        return pd.DataFrame()

    def _save_to_local_file(self, fund_code, df):
        """å°†DataFrameä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œè¦†ç›–æ—§æ–‡ä»¶"""
        file_path = os.path.join(FUND_DATA_DIR, f"{fund_code}.csv")
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        df.to_csv(file_path, index=False)
        logger.info("åŸºé‡‘ %s æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶: %s", fund_code, file_path)

    @tenacity.retry(
        stop=tenacity.stop_after_attempt(5),
        wait=tenacity.wait_fixed(10),
        retry=tenacity.retry_if_exception_type((requests.exceptions.RequestException, ValueError)),
        before_sleep=lambda retry_state: logger.info(f"é‡è¯•åŸºé‡‘ {retry_state.args[0]}ï¼Œç¬¬ {retry_state.attempt_number} æ¬¡")
    )
    def _fetch_fund_data(self, fund_code, latest_local_date=None):
        """
        ä»ç½‘ç»œè·å–åŸºé‡‘æ•°æ®ï¼Œå®ç°çœŸæ­£çš„å¢é‡æ›´æ–°ã€‚
        å¦‚æœ latest_local_date ä¸ä¸ºç©ºï¼Œåˆ™åªè·å–å…¶ä¹‹åçš„æ•°æ®ã€‚
        """
        all_new_data = []
        page_index = 1
        has_new_data = False
        
        while True:
            url = f"http://fundf10.eastmoney.com/F10DataApi.aspx?type=lsjz&code={fund_code}&page={page_index}&per=20"
            logger.info("æ­£åœ¨è·å–åŸºé‡‘ %s çš„ç¬¬ %d é¡µæ•°æ®...", fund_code, page_index)
            
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                response.raise_for_status()
                
                content_match = re.search(r'content:"(.*?)"', response.text, re.S)
                pages_match = re.search(r'pages:(\d+)', response.text)
                
                if not content_match or not pages_match:
                    logger.error("åŸºé‡‘ %s APIè¿”å›å†…å®¹æ ¼å¼ä¸æ­£ç¡®ï¼Œå¯èƒ½å·²æ— æ•°æ®æˆ–æ¥å£å˜æ›´", fund_code)
                    break

                raw_content_html = content_match.group(1).replace('\\"', '"')
                total_pages = int(pages_match.group(1))
                
                tables = pd.read_html(StringIO(raw_content_html))
                
                if not tables:
                    logger.warning("åŸºé‡‘ %s åœ¨ç¬¬ %d é¡µæœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼ï¼Œçˆ¬å–ç»“æŸ", fund_code, page_index)
                    break
                
                df_page = tables[0]
                df_page.columns = ['date', 'net_value', 'cumulative_net_value', 'daily_growth_rate', 'purchase_status', 'redemption_status', 'dividend']
                df_page = df_page[['date', 'net_value']].copy()
                df_page['date'] = pd.to_datetime(df_page['date'], errors='coerce')
                df_page['net_value'] = pd.to_numeric(df_page['net_value'], errors='coerce')
                df_page = df_page.dropna(subset=['date', 'net_value'])
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦å·²è·å–åˆ°æœ¬åœ°æœ€æ–°æ•°æ®ä¹‹å‰çš„æ•°æ®
                if latest_local_date:
                    new_df_page = df_page[df_page['date'].dt.date > latest_local_date]
                    if new_df_page.empty:
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”ä¹‹å‰å·²ç»å‘ç°è¿‡æ–°æ•°æ®ï¼Œåˆ™åœæ­¢çˆ¬å–
                        if has_new_data:
                            logger.info("åŸºé‡‘ %s å·²è·å–æ‰€æœ‰æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", fund_code)
                            break
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æ˜¯ç¬¬ä¸€é¡µï¼Œåˆ™è¯´æ˜æ²¡æœ‰æ–°æ•°æ®
                        elif page_index == 1:
                            logger.info("åŸºé‡‘ %s æ— æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", fund_code)
                            break
                    else:
                        has_new_data = True
                        all_new_data.append(new_df_page)
                        logger.info("ç¬¬ %d é¡µ: å‘ç° %d è¡Œæ–°æ•°æ®", page_index, len(new_df_page))
                else:
                    # å¦‚æœæ˜¯é¦–æ¬¡ä¸‹è½½ï¼Œåˆ™è·å–æ‰€æœ‰æ•°æ®
                    all_new_data.append(df_page)

                logger.info("åŸºé‡‘ %s æ€»é¡µæ•°: %d, å½“å‰é¡µ: %d, å½“å‰é¡µè¡Œæ•°: %d", fund_code, total_pages, page_index, len(df_page))
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œä¸”å½“å‰é¡µæ•°æ®æ¯”æœ€æ–°æ•°æ®æ—¥æœŸæ—©ï¼Œåˆ™ç»“æŸå¾ªç¯
                if latest_local_date and (df_page['date'].dt.date <= latest_local_date).any():
                    logger.info("åŸºé‡‘ %s å·²è¿½æº¯åˆ°æœ¬åœ°æ•°æ®ï¼Œå¢é‡çˆ¬å–ç»“æŸã€‚", fund_code)
                    break

                if page_index >= total_pages:
                    logger.info("åŸºé‡‘ %s å·²è·å–æ‰€æœ‰å†å²æ•°æ®ï¼Œå…± %d é¡µï¼Œçˆ¬å–ç»“æŸ", fund_code, total_pages)
                    break
                
                page_index += 1
                time_module.sleep(random.uniform(1, 2))  # å»¶é•¿sleepåˆ°1-2ç§’ï¼Œå‡å°‘é™é€Ÿé£é™©
                
            except requests.exceptions.RequestException as e:
                logger.error("åŸºé‡‘ %s APIè¯·æ±‚å¤±è´¥: %s", fund_code, str(e))
                raise
            except Exception as e:
                logger.error("åŸºé‡‘ %s APIæ•°æ®è§£æå¤±è´¥: %s", fund_code, str(e))
                raise

        # åˆå¹¶æ–°æ•°æ®å¹¶è¿”å›
        if all_new_data:
            new_combined_df = pd.concat(all_new_data, ignore_index=True)
            return new_combined_df[['date', 'net_value']]
        else:
            return pd.DataFrame()

    def _load_index_data_from_file(self):
        """
        ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å¤§ç›˜æŒ‡æ•°æ•°æ®
        """
        file_path = os.path.join(INDEX_DATA_DIR, f"{self.index_code}.csv")
        logger.info("æ­£åœ¨ä»æœ¬åœ°æ–‡ä»¶ %s åŠ è½½å¤§ç›˜æŒ‡æ•°æ•°æ®...", file_path)
        if not os.path.exists(file_path):
            logger.error("æœ¬åœ°å¤§ç›˜æŒ‡æ•°æ–‡ä»¶ %s ä¸å­˜åœ¨ï¼Œè¯·è¿è¡Œ download_index_data.py ä¸‹è½½ã€‚", file_path)
            return pd.DataFrame()
        
        try:
            df = pd.read_csv(file_path, parse_dates=['date'])
            df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
            logger.info("å¤§ç›˜æŒ‡æ•° %s æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± %d è¡Œï¼Œæœ€æ–°æ—¥æœŸä¸º: %s", self.index_code, len(df), df['date'].max().date())
            return df
        except Exception as e:
            logger.error("åŠ è½½æœ¬åœ°å¤§ç›˜æŒ‡æ•°æ–‡ä»¶ %s å¤±è´¥: %s", file_path, e)
            return pd.DataFrame()

    def _calculate_indicators(self, df):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¹¶ç”Ÿæˆç»“æœå­—å…¸"""
        if df is None or df.empty or len(df) < 26:
            return None

        df = df.sort_values(by='date', ascending=True)
        
        # MACD
        exp12 = df['net_value'].ewm(span=12, adjust=False).mean()
        exp26 = df['net_value'].ewm(span=26, adjust=False).mean()
        df['macd'] = exp12 - exp26
        df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()

        # å¸ƒæ—å¸¦
        window = 20
        df['bb_mid'] = df['net_value'].rolling(window=window, min_periods=1).mean()
        df['bb_std'] = df['net_value'].rolling(window=window, min_periods=1).std()
        df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * 2)
        df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * 2)
        
        # RSI
        delta = df['net_value'].diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        
        avg_gain = gain.rolling(window=14, min_periods=1).mean()
        avg_loss = loss.rolling(window=14, min_periods=1).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.nan)
        df['rsi'] = 100 - (100 / (1 + rs))

        # MA50
        df['ma50'] = df['net_value'].rolling(window=min(50, len(df)), min_periods=1).mean()
        df['ma_ratio'] = df['net_value'] / df['ma50']

        return df

    def _get_latest_signals(self, fund_code, df):
        """æ ¹æ®æœ€æ–°æ•°æ®è®¡ç®—ä¿¡å·"""
        try:
            processed_df = self._calculate_indicators(df)
            if processed_df is None:
                logger.warning("åŸºé‡‘ %s æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®¡ç®—", fund_code)
                return {
                    'fund_code': fund_code, 'latest_net_value': "æ•°æ®è·å–å¤±è´¥", 'rsi': np.nan, 'ma_ratio': np.nan,
                    'macd_diff': np.nan, 'bb_upper': np.nan, 'bb_lower': np.nan, 'bb_position': 'N/A', 'advice': "è§‚å¯Ÿ", 'action_signal': 'N/A'
                }
            
            latest_data = processed_df.iloc[-1]
            latest_net_value = latest_data['net_value']
            latest_rsi = latest_data['rsi']
            latest_ma50_ratio = latest_data['ma_ratio']
            latest_macd_diff = latest_data['macd'] - latest_data['signal']
            latest_bb_upper = latest_data['bb_upper']
            latest_bb_lower = latest_data['bb_lower']

            advice = "è§‚å¯Ÿ"
            if (not np.isnan(latest_rsi) and latest_rsi > 70) or \
               (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
               (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2):
                advice = "ç­‰å¾…å›è°ƒ"
            elif (not np.isnan(latest_rsi) and latest_rsi < 30) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.8):
                advice = "å¯åˆ†æ‰¹ä¹°å…¥"
            elif (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                advice = "å¯åˆ†æ‰¹ä¹°å…¥"
            elif (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 1) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff < 0):
                advice = "ç­‰å¾…å›è°ƒ"

            action_signal = "æŒæœ‰/è§‚å¯Ÿ"
            if not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.95:
                action_signal = "å¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 70) and \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff < 0):
                action_signal = "å¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 65) or \
                 (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2):
                action_signal = "å¼±å–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi < 35) and \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.9) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                action_signal = "å¼ºä¹°å…¥"
            elif (not np.isnan(latest_rsi) and latest_rsi < 45) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 1):
                action_signal = "å¼±ä¹°å…¥"

            # è®¡ç®—å¸ƒæ—å¸¦ä½ç½®
            bb_position = "ä¸­è½¨"
            if not np.isnan(latest_net_value) and not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper:
                bb_position = "ä¸Šè½¨ä¸Šæ–¹"
            elif not np.isnan(latest_net_value) and not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower:
                bb_position = "ä¸‹è½¨ä¸‹æ–¹"

            return {
                'fund_code': fund_code,
                'latest_net_value': latest_net_value,
                'rsi': latest_rsi,
                'ma_ratio': latest_ma50_ratio,
                'macd_diff': latest_macd_diff,
                'bb_upper': latest_bb_upper,
                'bb_lower': latest_bb_lower,
                'bb_position': bb_position,
                'advice': advice,
                'action_signal': action_signal
            }
        except Exception as e:
            logger.error("å¤„ç†åŸºé‡‘ %s æ—¶å‘ç”Ÿå¼‚å¸¸: %s", fund_code, str(e))
            return {
                'fund_code': fund_code,
                'latest_net_value': "æ•°æ®è·å–å¤±è´¥",
                'rsi': np.nan,
                'ma_ratio': np.nan,
                'macd_diff': np.nan,
                'bb_upper': np.nan,
                'bb_lower': np.nan,
                'bb_position': 'N/A',
                'advice': "è§‚å¯Ÿ",
                'action_signal': 'N/A'
            }

    def _analyze_index(self, index_df):
        """åˆ†æå¤§ç›˜æŒ‡æ•°ï¼Œè®¡ç®—æŠ€æœ¯æŒ‡æ ‡å’Œä¿¡å·"""
        logger.info("å¼€å§‹åˆ†æå¤§ç›˜æŒ‡æ•° %s...", self.index_code)
        if not index_df.empty:
            self.index_df = index_df
            result = self._get_latest_signals(self.index_code, self.index_df.tail(100))
            self.index_data = result
            logger.info("å¤§ç›˜æŒ‡æ•° %s åˆ†æå®Œæˆ", self.index_code)
        else:
            logger.error("å¤§ç›˜æŒ‡æ•° %s æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®", self.index_code)
            self.index_data = {
                'fund_code': self.index_code,
                'latest_net_value': "æ•°æ®è·å–å¤±è´¥",
                'rsi': np.nan,
                'ma_ratio': np.nan,
                'macd_diff': np.nan,
                'bb_upper': np.nan,
                'bb_lower': np.nan,
                'bb_position': 'N/A',
                'advice': "è§‚å¯Ÿ",
                'action_signal': 'N/A'
            }

    def _get_portfolio_signals(self, fund_data, max_positions=5):
        """
        æ ¹æ®ç»¼åˆè¯„åˆ†ç­›é€‰å‡ºå€¼å¾—ä¹°å…¥çš„åŸºé‡‘
        """
        buy_signals = []
        for code, data in fund_data.items():
            if data['action_signal'] in ["å¼ºä¹°å…¥", "å¼±ä¹°å…¥"] and not np.isnan(data['rsi']):
                score = self._calculate_buy_score(data)
                buy_signals.append({
                    'code': code,
                    'signal': data['action_signal'],
                    'score': score,
                    'rsi': data['rsi'],
                    'ma_ratio': data['ma_ratio']
                })
        
        # æŒ‰ç…§è¯„åˆ†é™åºæ’åˆ—ï¼Œå–å‰Nä¸ª
        buy_signals = sorted(buy_signals, key=lambda x: x['score'], reverse=True)
        
        return buy_signals[:max_positions]

    def _calculate_buy_score(self, data):
        """
        è®¡ç®—åŸºé‡‘ä¹°å…¥è¯„åˆ†
        RSIè¶Šä½åˆ†æ•°è¶Šé«˜ï¼ŒMA_Ratioè¶Šä½åˆ†æ•°è¶Šé«˜ï¼Œå¸ƒæ—å¸¦ä½ç½®è¶Šä½åˆ†æ•°è¶Šé«˜
        """
        score = 0
        
        # 1. RSIè¯„åˆ†: 40åˆ†
        if data['rsi'] < 30:
            score += 40
        elif data['rsi'] < 40:
            score += 30
        elif data['rsi'] < 50:
            score += 20
        
        # 2. MA_Ratioè¯„åˆ†: 40åˆ†
        if data['ma_ratio'] < 0.9:
            score += 40
        elif data['ma_ratio'] < 0.95:
            score += 30
        elif data['ma_ratio'] < 1.0:
            score += 20
        elif data['ma_ratio'] < 1.05:
            score += 10

        # 3. å¸ƒæ—å¸¦ä½ç½®è¯„åˆ†: 20åˆ†
        bb_position = data['bb_position']
        if bb_position == "ä¸‹è½¨ä¸‹æ–¹":
            score += 20
        elif bb_position == "ä¸­è½¨":
            score += 10
        else:
            score += 5
        
        return score

    def generate_portfolio_recommendation(self):
        """ç”ŸæˆæŠ•èµ„ç»„åˆæ¨è"""
        buy_candidates = self._get_portfolio_signals(self.fund_data, max_positions=3)
        
        with open(self.portfolio_output_file, 'w', encoding='utf-8') as f:
            f.write(f"# æŠ•èµ„ç»„åˆæ¨èæŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d')})\n\n")
            f.write("---")
            f.write(f"### å¤§ç›˜æŒ‡æ•° {self.index_code} å¸‚åœºæƒ…ç»ª\n\n")
            f.write(f"ğŸ“ˆ **æœ€æ–°å‡€å€¼**: {float(self.index_data['latest_net_value']):.2f}\n")
            f.write(f"ğŸ“Š **RSI**: {self.index_data['rsi']:.2f}\n")
            f.write(f"ğŸ“‰ **MA_Ratio**: {self.index_data['ma_ratio']:.2f}\n")
            f.write(f"ğŸ’¡ **å½“å‰ä¿¡å·**: {self.index_data['action_signal']} | {self.index_data['advice']}\n")
            f.write("---")
            f.write("\n## æ¨èåŸºé‡‘åˆ—è¡¨\n\n")
            
            if buy_candidates:
                f.write("| åºå· | ä¿¡å· | åŸºé‡‘ä»£ç  | è¯„åˆ† | RSI | MA_Ratio |\n")
                f.write("|------|------|----------|------|-----|----------|\n")
                for i, candidate in enumerate(buy_candidates, 1):
                    signal_emoji = "ğŸŸ¢ å¼ºä¹°å…¥" if candidate['signal'] == "å¼ºä¹°å…¥" else "ğŸŸ¡ å¼±ä¹°å…¥"
                    f.write(f"| {i} | {signal_emoji} | {candidate['code']} | {candidate['score']:.0f} | {candidate['rsi']:.1f} | {candidate['ma_ratio']:.2f} |\n")
                
                if buy_candidates:
                    suggested_amount = buy_candidates[0]['score'] // 10 * 100
                    f.write(f"\n## å»ºè®®åˆ†é…\n")
                    f.write(f"ğŸ’° å»ºè®®æ¯æ”¯åŸºé‡‘åˆ†é…: {suggested_amount} å…ƒ\n\n")
                    f.write(f"ğŸ“ˆ ä»Šæ—¥ä¹°å…¥æœºä¼š: {len(buy_candidates)} / {len(self.fund_codes)}\n\n")
            else:
                f.write("## æ¨èç»“æœ\n")
                f.write("âŒ ä»Šæ—¥æ— ç¬¦åˆæ¡ä»¶çš„ä¹°å…¥æœºä¼šï¼Œå»ºè®®è§‚æœ›\n\n")
                f.write(f"ğŸ“Š æ€»æ‰«æåŸºé‡‘æ•°: {len(self.fund_codes)}\n\n")
        
        logger.info("æŠ•èµ„ç»„åˆæ¨èæŠ¥å‘Šç”Ÿæˆå®Œæˆ: %s", self.portfolio_output_file)

    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        logger.info("æ­£åœ¨ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š: %s", self.output_file)
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write(f"# å¸‚åœºç›‘æ§æŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d')})\n\n")
            f.write("---")
            f.write(f"### å¤§ç›˜æŒ‡æ•° {self.index_code} å¸‚åœºæƒ…ç»ª\n\n")
            f.write(f"ğŸ“ˆ **æœ€æ–°å‡€å€¼**: {self.index_data['latest_net_value']:.2f}\n")
            f.write(f"ğŸ“Š **RSI**: {self.index_data['rsi']:.2f}\n")
            f.write(f"ğŸ“‰ **MA_Ratio**: {self.index_data['ma_ratio']:.2f}\n")
            f.write(f"ğŸ’¡ **å½“å‰ä¿¡å·**: {self.index_data['action_signal']} | {self.index_data['advice']}\n")
            f.write("---")
            f.write("\n## åŸºé‡‘æ•°æ®åˆ†æ\n\n")
            f.write("| åŸºé‡‘ä»£ç  | æœ€æ–°å‡€å€¼ | RSI | MA50æ¯”ä¾‹ | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | å»ºè®® | æ“ä½œä¿¡å· |\n")
            f.write("|----------|----------|-----|----------|----------|------------|------|----------|\n")
            
            for code, data in self.fund_data.items():
                line = (
                    f"| {data['fund_code']} | {data['latest_net_value']:.4f} | {data['rsi']:.2f} | {data['ma_ratio']:.2f} | "
                    f"{'é‡‘å‰' if data['macd_diff'] > 0 else 'æ­»å‰' if data['macd_diff'] < 0 else 'æ— ä¿¡å·'} | "
                    f"{data['bb_position']} | {data['advice']} | {data['action_signal']} |\n"
                )
                f.write(line)
        
        logger.info("è¯¦ç»†æŠ¥å‘Šç”Ÿæˆå®Œæˆ: %s", self.output_file)

    def generate_backtest_report(self):
        """ç”Ÿæˆå›æµ‹æŠ¥å‘Š"""
        logger.info("å¼€å§‹ç”Ÿæˆå›æµ‹æŠ¥å‘Š: %s", self.backtest_output_file)
        results = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            future_to_code = {executor.submit(self._run_backtest_for_fund, code): code for code in self.fund_codes}
            for future in concurrent.futures.as_completed(future_to_code):
                fund_code = future_to_code[future]
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                except Exception as e:
                    logger.error("å›æµ‹åŸºé‡‘ %s æ—¶å‘ç”Ÿå¼‚å¸¸: %s", fund_code, e)
        
        if not results:
            logger.warning("æ²¡æœ‰å¯ç”¨äºå›æµ‹çš„åŸºé‡‘æ•°æ®ã€‚")
            with open(self.backtest_output_file, 'w', encoding='utf-8') as f:
                f.write("# å†å²å›æµ‹æŠ¥å‘Š\n\n")
                f.write("---")
                f.write("\n\nâŒ æ²¡æœ‰å¯ç”¨äºå›æµ‹çš„åŸºé‡‘æ•°æ®ã€‚\n")
            return
        
        df_results = pd.DataFrame(results)
        df_results.sort_values(by='cagr', ascending=False, inplace=True)
        
        # ä¿å­˜è¯¦ç»†çš„å›æµ‹ç»“æœåˆ°CSV
        df_results.to_csv('backtest_results.csv', index=False, float_format='%.4f')

        with open(self.backtest_output_file, 'w', encoding='utf-8') as f:
            f.write("# å†å²å›æµ‹æŠ¥å‘Š\n\n")
            f.write("---")
            f.write("\n\n## ç»¼åˆè¡¨ç°æ’å (æŒ‰å¹´åŒ–æ”¶ç›Šç‡)\n\n")
            f.write(df_results.to_markdown(index=False, floatfmt=".2f"))
        
        logger.info("å›æµ‹æŠ¥å‘Šç”Ÿæˆå®Œæˆ: %s", self.backtest_output_file)
    
    def _run_backtest_for_fund(self, fund_code):
        df = self._read_local_data(fund_code)
        if df.empty or len(df) < 100:
            logger.warning(f"åŸºé‡‘ {fund_code} æ•°æ®ä¸è¶³ï¼Œæ— æ³•å›æµ‹ã€‚")
            return None
        
        backtest_result = self._backtest_strategy(fund_code, df)
        backtest_result['fund_code'] = fund_code
        logger.info(f"åŸºé‡‘ {fund_code} å›æµ‹ç»“æœ: ç´¯è®¡å›æŠ¥={backtest_result['cum_return']:.2f}, æœ€å¤§å›æ’¤={backtest_result['max_drawdown']:.2f}, å¤æ™®æ¯”ç‡={backtest_result['sharpe_ratio']:.2f}, èƒœç‡={backtest_result['win_rate']:.2f}, å¹´åŒ–æ”¶ç›Šç‡={backtest_result['cagr']:.2f}, äº¤æ˜“æ¬¡æ•°={backtest_result['total_trades']}")
        
        return backtest_result

    def _backtest_strategy(self, fund_code, df):
        """å†å²å›æµ‹ç­–ç•¥æ€§èƒ½"""
        if df is None or df.empty or len(df) < 100:
            logger.warning("åŸºé‡‘ %s æ•°æ®ä¸è¶³ï¼Œæ— æ³•å›æµ‹", fund_code)
            return {"cum_return": np.nan, "max_drawdown": np.nan, "sharpe_ratio": np.nan, "win_rate": np.nan, "cagr": np.nan, "total_trades": 0}

        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        df = self._calculate_indicators(df)
        df = df.dropna()
        # å…³é”®ä¿®å¤ï¼šé‡ç½®ç´¢å¼•ä»¥ç¡®ä¿åç»­å¾ªç¯çš„.ilocæ­£å¸¸å·¥ä½œ
        df.reset_index(drop=True, inplace=True)

        # å¢åŠ ä¸€ä¸ªæ£€æŸ¥ï¼Œç¡®ä¿dropnaåä»æœ‰è¶³å¤Ÿçš„æ•°æ®
        if df.empty or len(df) < 2:
            logger.warning("åŸºé‡‘ %s è®¡ç®—æŒ‡æ ‡åæ•°æ®ä¸è¶³ï¼Œæ— æ³•å›æµ‹", fund_code)
            return {"cum_return": np.nan, "max_drawdown": np.nan, "sharpe_ratio": np.nan, "win_rate": np.nan, "cagr": np.nan, "total_trades": 0}

        # æ¨¡æ‹Ÿäº¤æ˜“
        position = 0
        buy_price = 0
        trades = []
        equity = [1.0] * len(df)
        for i in range(1, len(df)):
            latest_data = df.iloc[i]
            latest_net_value = latest_data['net_value']
            
            # æœ€å¤§å›æ’¤è®¡ç®—
            prev_net_value = df['net_value'].iloc[i-1]
            if prev_net_value != 0:
                equity[i] = equity[i-1] * (1 + (latest_net_value - prev_net_value) / prev_net_value)
            else:
                equity[i] = equity[i-1]

            # æ­¢æŸé€»è¾‘
            if position == 1 and (latest_net_value / buy_price) < 0.90:  # æ­¢æŸ10%
                sell_price = latest_net_value
                ret = (sell_price - buy_price) / buy_price
                trades.append({'buy_date': df.iloc[i-1]['date'], 'sell_date': df.iloc[i]['date'], 'return': ret, 'type': 'stop_loss'})
                position = 0
                buy_price = 0
                continue # ç»§ç»­ä¸‹ä¸€å¤©

            # äº¤æ˜“ä¿¡å·é€»è¾‘
            latest_rsi = latest_data['rsi']
            latest_ma_ratio = latest_data['ma_ratio']
            latest_macd_diff = latest_data['macd'] - latest_data['signal']
            
            # ä¹°å…¥æ¡ä»¶ï¼šRSIä½äº45æˆ–MA_Ratioä½äº1ï¼Œä¸”MACDé‡‘å‰
            if position == 0 and \
               (latest_rsi < 45 or latest_ma_ratio < 1) and \
               (df.iloc[i-1]['macd'] - df.iloc[i-1]['signal'] <= 0 and latest_macd_diff > 0):
                
                position = 1
                buy_price = latest_net_value
                
            # å–å‡ºæ¡ä»¶ï¼šRSIé«˜äº65æˆ–MA_Ratioé«˜äº1.2ï¼Œä¸”MACDæ­»å‰
            elif position == 1 and \
                 (latest_rsi > 65 or latest_ma_ratio > 1.2) and \
                 (df.iloc[i-1]['macd'] - df.iloc[i-1]['signal'] >= 0 and latest_macd_diff < 0):
                
                sell_price = latest_net_value
                ret = (sell_price - buy_price) / buy_price
                trades.append({'buy_date': df.iloc[i-1]['date'], 'sell_date': df.iloc[i]['date'], 'return': ret, 'type': 'normal'})
                position = 0
                buy_price = 0
        
        # å¦‚æœå›æµ‹ç»“æŸæ—¶ä»æœ‰æŒä»“ï¼Œåˆ™ä»¥æœ€åä¸€å¤©å‡€å€¼æ¸…ä»“
        if position == 1:
            sell_price = df.iloc[-1]['net_value']
            ret = (sell_price - buy_price) / buy_price
            trades.append({'buy_date': buy_price, 'sell_date': sell_price, 'return': ret, 'type': 'final_sell'})

        # è®¡ç®—å›æµ‹æŒ‡æ ‡
        if not trades:
            return {"cum_return": np.nan, "max_drawdown": np.nan, "sharpe_ratio": np.nan, "win_rate": np.nan, "cagr": np.nan, "total_trades": 0}

        cum_return = np.product([1 + t['return'] for t in trades]) - 1
        
        equity_series = pd.Series(equity)
        max_drawdown = (equity_series / equity_series.cummax() - 1).min()
        
        win_trades = [t for t in trades if t['return'] > 0]
        win_rate = len(win_trades) / len(trades) if trades else 0
        
        daily_returns = df['net_value'].pct_change().dropna()
        if daily_returns.empty:
             sharpe_ratio = np.nan
             cagr = np.nan
        else:
            risk_free_rate = 0.03 / 252 # å‡è®¾å¹´åŒ–æ— é£é™©åˆ©ç‡ä¸º3%ï¼Œé™¤ä»¥252ä¸ªäº¤æ˜“æ—¥
            sharpe_ratio = (daily_returns.mean() - risk_free_rate) / daily_returns.std() * np.sqrt(252)
            
            # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡ (CAGR)
            start_date = df['date'].iloc[0]
            end_date = df['date'].iloc[-1]
            total_years = (end_date - start_date).days / 365.25
            cagr = ((1 + cum_return) ** (1 / total_years)) - 1 if total_years > 0 else 0

        return {
            "cum_return": cum_return,
            "max_drawdown": max_drawdown,
            "sharpe_ratio": sharpe_ratio,
            "win_rate": win_rate,
            "cagr": cagr,
            "total_trades": len(trades)
        }

    def run(self):
        """ä¸»æ‰§è¡Œæµç¨‹"""
        try:
            # æ­¥éª¤ 1: åŠ è½½æœ¬åœ°æŒ‡æ•°æ•°æ®
            index_df = self._load_index_data_from_file()
            self._analyze_index(index_df)

            # æ­¥éª¤ 2: è§£ææ¨èåŸºé‡‘ä»£ç 
            self._parse_report()
            if not self.fund_codes:
                logger.error("æ²¡æœ‰æå–åˆ°ä»»ä½•åŸºé‡‘ä»£ç ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
                return

            # æ­¥éª¤ 3: é¢„åŠ è½½æœ¬åœ°åŸºé‡‘æ•°æ®å¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸‹è½½
            logger.info("å¼€å§‹é¢„åŠ è½½æœ¬åœ°ç¼“å­˜æ•°æ®...")
            fund_codes_to_fetch = []
            expected_latest_date = self._get_expected_latest_date()
            min_data_points = 26 # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            for fund_code in self.fund_codes:
                local_df = self._read_local_data(fund_code)
                if not local_df.empty:
                    latest_local_date = local_df['date'].max().date()
                    data_points = len(local_df)
                    # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ€æ–°ä¸”å®Œæ•´
                    if latest_local_date >= expected_latest_date and data_points >= min_data_points:
                        logger.info("åŸºé‡‘ %s çš„æœ¬åœ°æ•°æ®å·²æ˜¯æœ€æ–° (%s, æœŸæœ›: %s) ä¸”æ•°æ®é‡è¶³å¤Ÿ (%d è¡Œ)ï¼Œç›´æ¥åŠ è½½ã€‚", fund_code, latest_local_date, expected_latest_date, data_points)
                        self.fund_data[fund_code] = self._get_latest_signals(fund_code, local_df.tail(100))
                        continue
                    else:
                        if latest_local_date < expected_latest_date:
                            logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®å·²è¿‡æ—¶ï¼ˆæœ€æ–°æ—¥æœŸä¸º %sï¼ŒæœŸæœ› %sï¼‰ï¼Œéœ€è¦ä»ç½‘ç»œè·å–æ–°æ•°æ®ã€‚", fund_code, latest_local_date, expected_latest_date)
                        if data_points < min_data_points:
                            logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®é‡ä¸è¶³ï¼ˆä»… %d è¡Œï¼Œéœ€è‡³å°‘ %d è¡Œï¼‰ï¼Œéœ€è¦ä»ç½‘ç»œè·å–ã€‚", fund_code, data_points, min_data_points)
                else:
                    logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®ä¸å­˜åœ¨ï¼Œéœ€è¦ä»ç½‘ç»œè·å–ã€‚", fund_code)
                fund_codes_to_fetch.append(fund_code)
            
            # æ­¥éª¤ 4: å¤šçº¿ç¨‹ç½‘ç»œä¸‹è½½å’Œå¤„ç†
            if fund_codes_to_fetch:
                logger.info("å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹è·å– %d ä¸ªåŸºé‡‘çš„æ–°æ•°æ®...", len(fund_codes_to_fetch))
                with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                    future_to_code = {executor.submit(self._process_single_fund, code): code for code in fund_codes_to_fetch}
                    for future in concurrent.futures.as_completed(future_to_code):
                        fund_code = future_to_code[future]
                        try:
                            result = future.result()
                            if result:
                                self.fund_data[fund_code] = result
                        except Exception as e:
                            logger.error("å¤„ç†åŸºé‡‘ %s æ•°æ®æ—¶å‡ºé”™: %s", fund_code, str(e))
                            self.fund_data[fund_code] = {
                                'fund_code': fund_code,
                                'latest_net_value': "æ•°æ®è·å–å¤±è´¥",
                                'rsi': np.nan,
                                'ma_ratio': np.nan,
                                'macd_diff': np.nan,
                                'bb_upper': np.nan,
                                'bb_lower': np.nan,
                                'bb_position': 'N/A',
                                'advice': "è§‚å¯Ÿ",
                                'action_signal': 'N/A'
                            }
            else:
                logger.info("æ‰€æœ‰åŸºé‡‘æ•°æ®å‡æ¥è‡ªæœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€ç½‘ç»œä¸‹è½½ã€‚")

            if len(self.fund_data) > 0:
                logger.info("æ‰€æœ‰åŸºé‡‘æ•°æ®å¤„ç†å®Œæˆã€‚")
            else:
                logger.error("æ‰€æœ‰åŸºé‡‘æ•°æ®å‡è·å–å¤±è´¥ã€‚")
            
            # æ­¥éª¤ 5: ç”ŸæˆæŠ¥å‘Š
            self.generate_portfolio_recommendation()
            self.generate_detailed_report()
            self.generate_backtest_report()

        except Exception as e:
            logger.exception("è„šæœ¬æ‰§è¡Œå¤±è´¥: %s", e)

    def _process_single_fund(self, fund_code):
        """å¤„ç†å•ä¸ªåŸºé‡‘æ•°æ®ï¼šè¯»å–æœ¬åœ°ï¼Œä¸‹è½½å¢é‡ï¼Œåˆå¹¶ï¼Œä¿å­˜ï¼Œå¹¶è®¡ç®—ä¿¡å·"""
        local_df = self._read_local_data(fund_code)
        latest_local_date = local_df['date'].max().date() if not local_df.empty else None
        
        new_df = self._fetch_fund_data(fund_code, latest_local_date)
        
        if not new_df.empty:
            df_final = pd.concat([local_df, new_df]).drop_duplicates(subset=['date'], keep='last').sort_values(by='date', ascending=True)
            self._save_to_local_file(fund_code, df_final)
            return self._get_latest_signals(fund_code, df_final.tail(100))
        elif not local_df.empty:
            # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æœ¬åœ°æœ‰æ•°æ®ï¼Œåˆ™ä½¿ç”¨æœ¬åœ°æ•°æ®è®¡ç®—ä¿¡å·
            logger.info("åŸºé‡‘ %s æ— æ–°æ•°æ®ï¼Œä½¿ç”¨æœ¬åœ°å†å²æ•°æ®è¿›è¡Œåˆ†æ", fund_code)
            return self._get_latest_signals(fund_code, local_df.tail(100))
        else:
            # å¦‚æœæ—¢æ²¡æœ‰æ–°æ•°æ®ï¼Œæœ¬åœ°åˆæ²¡æœ‰æ•°æ®ï¼Œåˆ™è¿”å›å¤±è´¥
            logger.error("åŸºé‡‘ %s æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œä¸”æœ¬åœ°æ— ç¼“å­˜", fund_code)
            return None

if __name__ == "__main__":
    try:
        logger.info("è„šæœ¬å¯åŠ¨")
        monitor = MarketMonitor()
        monitor.run()
        logger.info("è„šæœ¬è¿è¡Œç»“æŸ")
    except Exception as e:
        logger.exception("è„šæœ¬è¿è¡Œå¤±è´¥: %s", e)
