import pandas as pd
import numpy as np
import re
import os
import logging
from datetime import datetime, timedelta, time
import random
from io import StringIO
import requests
import tenacity
import concurrent.futures
import time as time_module
import json
from typing import Dict, Optional, Tuple

# å®šä¹‰æœ¬åœ°æ•°æ®å­˜å‚¨ç›®å½•
FUND_DATA_DIR = 'fund_data'
INDEX_DATA_DIR = 'index_data'
if not os.path.exists(FUND_DATA_DIR):
    os.makedirs(FUND_DATA_DIR)
if not os.path.exists(INDEX_DATA_DIR):
    os.makedirs(INDEX_DATA_DIR)
    
# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('market_monitor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MarketMonitor:
    def __init__(self, report_file='analysis_report.md', output_file='market_monitor_report.md'):
        self.report_file = report_file
        self.output_file = output_file
        self.backtest_output_file = 'backtest_report.md'
        self.portfolio_output_file = 'portfolio_recommendation.md'
        self.fund_codes = []
        self.fund_data = {}
        self.index_code = '000300'  # æ²ªæ·±300æŒ‡æ•°ä»£ç 
        self.index_data = {}
        self.index_df = pd.DataFrame()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36'
        }
        
        # ç¡¬ç¼–ç é…ç½®å‚æ•°
        self.max_workers = 5
        self.retry_attempts = 5
        self.retry_wait_seconds = 10
        self.request_timeout = 30
        self.sleep_min = 1
        self.sleep_max = 2
        
        self.min_data_points = 26
        self.max_consecutive_missing_days = 5
        self.net_value_min = 0.01
        self.net_value_max = 1000.0
        
        self.macd_fast = 12
        self.macd_slow = 26
        self.macd_signal = 9
        self.bollinger_window = 20
        self.bollinger_std = 2
        self.rsi_window = 14
        self.ma_window = 50
        self.rsi_oversold = 30
        self.rsi_overbought = 70
        self.ma_ratio_high = 1.2
        self.ma_ratio_low = 0.8
        
        self.stop_loss_percent = 0.10
        self.rsi_buy_threshold = 45
        self.rsi_sell_threshold = 65
        self.ma_ratio_buy_threshold = 1.0
        self.ma_ratio_sell_threshold = 1.2
        self.rsi_buy_strong = 35
        self.rsi_sell_weak = 65
        self.ma_ratio_strong_sell = 1.2
        self.ma_ratio_strong_buy = 0.9
        
        self.min_backtest_data = 100
        self.risk_free_rate = 0.03
        self.trading_days_per_year = 252
        
        self.max_positions = 5
        self.suggested_allocation_base = 100

    def _get_expected_latest_date(self):
        """æ ¹æ®å½“å‰æ—¶é—´ç¡®å®šæœŸæœ›çš„æœ€æ–°æ•°æ®æ—¥æœŸ"""
        now = datetime.now()
        # å‡è®¾å‡€å€¼æ›´æ–°æ—¶é—´ä¸ºæ™šä¸Š21:00
        update_time = time(21, 0)
        if now.time() < update_time:
            # å¦‚æœå½“å‰æ—¶é—´æ—©äº21:00ï¼Œåˆ™æœŸæœ›æœ€æ–°æ—¥æœŸä¸ºæ˜¨å¤©
            expected_date = now.date() - timedelta(days=1)
        else:
            # å¦åˆ™ï¼ŒæœŸæœ›æœ€æ–°æ—¥æœŸä¸ºä»Šå¤©
            expected_date = now.date()
        logger.info("å½“å‰æ—¶é—´: %s, æœŸæœ›æœ€æ–°æ•°æ®æ—¥æœŸ: %s", now.strftime('%Y-%m-%d %H:%M:%S'), expected_date)
        return expected_date

    def _validate_fund_data(self, df: pd.DataFrame, fund_code: str) -> Tuple[bool, str]:
        """
        éªŒè¯åŸºé‡‘æ•°æ®çš„å®Œæ•´æ€§å’Œåˆç†æ€§
        è¿”å› (æ˜¯å¦é€šè¿‡éªŒè¯, é”™è¯¯ä¿¡æ¯)
        """
        if df.empty:
            return False, f"åŸºé‡‘ {fund_code} æ•°æ®ä¸ºç©º"
        
        # 1. æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['date', 'net_value']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return False, f"åŸºé‡‘ {fund_code} ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}"
        
        # 2. æ£€æŸ¥æ•°æ®è¡Œæ•°
        if len(df) < self.min_data_points:
            return False, f"åŸºé‡‘ {fund_code} æ•°æ®è¡Œæ•°ä¸è¶³ ({len(df)} < {self.min_data_points})"
        
        # 3. æ£€æŸ¥æ—¥æœŸæ ¼å¼å’Œæ’åº
        try:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
            invalid_dates = df[df['date'].isna()]
            if not invalid_dates.empty:
                return False, f"åŸºé‡‘ {fund_code} åŒ…å« {len(invalid_dates)} æ¡æ— æ•ˆæ—¥æœŸ"
            
            # æ£€æŸ¥æ—¥æœŸæ˜¯å¦è¿ç»­é€’å¢
            df_sorted = df.sort_values('date').reset_index(drop=True)
            date_diffs = df_sorted['date'].diff().dt.days
            consecutive_missing = (date_diffs > 1).sum()
            if consecutive_missing > self.max_consecutive_missing_days:
                logger.warning("åŸºé‡‘ %s å­˜åœ¨ %d å¤©ä»¥ä¸Šçš„æ—¥æœŸæ–­ç‚¹", fund_code, consecutive_missing)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æ—¥æœŸ
            duplicates = df_sorted[df_sorted.duplicated(subset=['date'], keep=False)]
            if not duplicates.empty:
                logger.warning("åŸºé‡‘ %s å­˜åœ¨ %d æ¡é‡å¤æ—¥æœŸï¼Œå·²å»é‡", fund_code, len(duplicates))
                df_sorted = df_sorted.drop_duplicates(subset=['date'], keep='last')
        except Exception as e:
            return False, f"åŸºé‡‘ {fund_code} æ—¥æœŸè§£æå¤±è´¥: {e}"
        
        # 4. æ£€æŸ¥å‡€å€¼æ•°æ®
        try:
            df_sorted['net_value'] = pd.to_numeric(df_sorted['net_value'], errors='coerce')
            invalid_values = df_sorted[df_sorted['net_value'].isna()]
            if not invalid_values.empty:
                return False, f"åŸºé‡‘ {fund_code} åŒ…å« {len(invalid_values)} æ¡æ— æ•ˆå‡€å€¼"
            
            # æ£€æŸ¥å‡€å€¼èŒƒå›´
            out_of_range = df_sorted[
                (df_sorted['net_value'] < self.net_value_min) |
                (df_sorted['net_value'] > self.net_value_max)
            ]
            if not out_of_range.empty:
                logger.warning("åŸºé‡‘ %s å­˜åœ¨ %d æ¡å‡€å€¼è¶…å‡ºèŒƒå›´çš„å€¼", fund_code, len(out_of_range))
            
            # æ£€æŸ¥å‡€å€¼æ˜¯å¦å•è°ƒé€’å¢
            net_value_diffs = df_sorted['net_value'].diff()
            negative_diffs = net_value_diffs[net_value_diffs < 0]
            if not negative_diffs.empty:
                logger.warning("åŸºé‡‘ %s å­˜åœ¨ %d æ¬¡å‡€å€¼è´Ÿå¢é•¿", fund_code, len(negative_diffs))
                
        except Exception as e:
            return False, f"åŸºé‡‘ %s å‡€å€¼è§£æå¤±è´¥: %s", fund_code, e
        
        # 5. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        total_days = (df_sorted['date'].max() - df_sorted['date'].min()).days
        data_coverage = len(df_sorted) / (total_days + 1) * 100
        if data_coverage < 70:  # æ•°æ®è¦†ç›–ç‡ä½äº70%æ—¶è­¦å‘Š
            logger.warning("åŸºé‡‘ %s æ•°æ®è¦†ç›–ç‡è¾ƒä½: %.1f%%", fund_code, data_coverage)
        
        logger.info("åŸºé‡‘ %s æ•°æ®éªŒè¯é€šè¿‡: %d è¡Œæ•°æ®, è¦†ç›–ç‡ %.1f%%", fund_code, len(df_sorted), data_coverage)
        return True, ""

    def _parse_report(self, report_path='analysis_report.md'):
        """ä» analysis_report.md æå–æ¨èåŸºé‡‘ä»£ç """
        logger.info("æ­£åœ¨è§£æ %s è·å–æ¨èåŸºé‡‘ä»£ç ...", report_path)
        if not os.path.exists(report_path):
            logger.error("æŠ¥å‘Šæ–‡ä»¶ %s ä¸å­˜åœ¨", report_path)
            raise FileNotFoundError(f"{report_path} ä¸å­˜åœ¨")
        
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            pattern = re.compile(r'(?:^\| +(\d{6})|### åŸºé‡‘ (\d{6}))', re.M)
            matches = pattern.findall(content)

            extracted_codes = set()
            for match in matches:
                code = match[0] if match[0] else match[1]
                extracted_codes.add(code)
            
            sorted_codes = sorted(list(extracted_codes))
            self.fund_codes = sorted_codes[:1000]
            
            if not self.fund_codes:
                logger.warning("æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆåŸºé‡‘ä»£ç ï¼Œè¯·æ£€æŸ¥ analysis_report.md")
            else:
                logger.info("æå–åˆ° %d ä¸ªåŸºé‡‘ï¼ˆæµ‹è¯•é™åˆ¶å‰1000ä¸ªï¼‰: %s", len(self.fund_codes), self.fund_codes)
            
        except Exception as e:
            logger.error("è§£ææŠ¥å‘Šæ–‡ä»¶å¤±è´¥: %s", e)
            raise

    def _read_local_data(self, fund_code):
        """è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨åˆ™è¿”å›DataFrame"""
        file_path = os.path.join(FUND_DATA_DIR, f"{fund_code}.csv")
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path, parse_dates=['date'])
                # éªŒè¯æœ¬åœ°æ•°æ®
                is_valid, error_msg = self._validate_fund_data(df, fund_code)
                if is_valid:
                    df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
                    logger.info("æœ¬åœ°å·²å­˜åœ¨åŸºé‡‘ %s æ•°æ®ï¼Œå…± %d è¡Œï¼Œæœ€æ–°æ—¥æœŸä¸º: %s", fund_code, len(df), df['date'].max().date())
                    return df
                else:
                    logger.warning("æœ¬åœ°åŸºé‡‘ %s æ•°æ®éªŒè¯å¤±è´¥: %sï¼Œåˆ é™¤æ— æ•ˆæ–‡ä»¶", fund_code, error_msg)
                    try:
                        os.remove(file_path)
                    except:
                        pass
                    return pd.DataFrame()
            except Exception as e:
                logger.warning("è¯»å–æœ¬åœ°æ–‡ä»¶ %s å¤±è´¥: %s", file_path, e)
                # åˆ é™¤æŸåçš„æ–‡ä»¶
                try:
                    os.remove(file_path)
                except:
                    pass
        return pd.DataFrame()
    
    def _load_index_data_from_file(self):
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æŒ‡æ•°æ•°æ®"""
        file_path = os.path.join(INDEX_DATA_DIR, f"{self.index_code}.csv")
        if os.path.exists(file_path):
            try:
                self.index_df = pd.read_csv(file_path, parse_dates=['date'])
                self.index_df = self.index_df.sort_values(by='date', ascending=True).reset_index(drop=True)
                logger.info("å¤§ç›˜æŒ‡æ•° %s æ•°æ®åŠ è½½æˆåŠŸ, å…± %d è¡Œ, æœ€æ–°æ—¥æœŸä¸º: %s", self.index_code, len(self.index_df), self.index_df['date'].max().date())
                return True
            except Exception as e:
                logger.error("åŠ è½½å¤§ç›˜æŒ‡æ•°æ•°æ®å¤±è´¥: %s", e)
        return False

    def _save_to_local_file(self, fund_code, df):
        """å°†DataFrameä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œè¦†ç›–æ—§æ–‡ä»¶"""
        # ä¿å­˜å‰å†æ¬¡éªŒè¯æ•°æ®
        is_valid, error_msg = self._validate_fund_data(df, fund_code)
        if not is_valid:
            logger.error("ä¿å­˜å‰æ•°æ®éªŒè¯å¤±è´¥: %s", error_msg)
            return False
        
        file_path = os.path.join(FUND_DATA_DIR, f"{fund_code}.csv")
        try:
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            df.to_csv(file_path, index=False)
            logger.info("åŸºé‡‘ %s æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶: %s", fund_code, file_path)
            return True
        except Exception as e:
            logger.error("ä¿å­˜åŸºé‡‘ %s æ•°æ®å¤±è´¥: %s", fund_code, e)
            return False

    @tenacity.retry(
        stop=tenacity.stop_after_attempt(5),
        wait=tenacity.wait_fixed(10),
        retry=tenacity.retry_if_exception_type((requests.exceptions.RequestException, ValueError)),
        before_sleep=lambda retry_state: logger.info(f"é‡è¯•åŸºé‡‘ {retry_state.args[0]}ï¼Œç¬¬ {retry_state.attempt_number} æ¬¡")
    )
    def _fetch_fund_data(self, fund_code, latest_local_date=None):
        """
        ä»ç½‘ç»œè·å–åŸºé‡‘æ•°æ®ï¼Œå®ç°çœŸæ­£çš„å¢é‡æ›´æ–°ã€‚
        å¦‚æœ latest_local_date ä¸ä¸ºç©ºï¼Œåˆ™åªè·å–å…¶ä¹‹åçš„æ•°æ®ã€‚
        """
        all_new_data = []
        page_index = 1
        has_new_data = False
        
        while True:
            url = f"http://fundf10.eastmoney.com/F10DataApi.aspx?type=lsjz&code={fund_code}&page={page_index}&per=20"
            logger.info("æ­£åœ¨è·å–åŸºé‡‘ %s çš„ç¬¬ %d é¡µæ•°æ®...", fund_code, page_index)
            
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                response.raise_for_status()
                
                content_match = re.search(r'content:"(.*?)"', response.text, re.S)
                pages_match = re.search(r'pages:(\d+)', response.text)
                
                if not content_match or not pages_match:
                    logger.error("åŸºé‡‘ %s APIè¿”å›å†…å®¹æ ¼å¼ä¸æ­£ç¡®ï¼Œå¯èƒ½å·²æ— æ•°æ®æˆ–æ¥å£å˜æ›´", fund_code)
                    break

                raw_content_html = content_match.group(1).replace('\\"', '"')
                total_pages = int(pages_match.group(1))
                
                tables = pd.read_html(StringIO(raw_content_html))
                
                if not tables:
                    logger.warning("åŸºé‡‘ %s åœ¨ç¬¬ %d é¡µæœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼ï¼Œçˆ¬å–ç»“æŸ", fund_code, page_index)
                    break
                
                df_page = tables[0]
                df_page.columns = ['date', 'net_value', 'cumulative_net_value', 'daily_growth_rate', 'purchase_status', 'redemption_status', 'dividend']
                df_page = df_page[['date', 'net_value']].copy()
                df_page['date'] = pd.to_datetime(df_page['date'], errors='coerce')
                df_page['net_value'] = pd.to_numeric(df_page['net_value'], errors='coerce')
                df_page = df_page.dropna(subset=['date', 'net_value'])
                
                # éªŒè¯å•é¡µæ•°æ®
                if not df_page.empty:
                    is_valid, error_msg = self._validate_fund_data(df_page, f"{fund_code}_page{page_index}")
                    if not is_valid:
                        logger.warning("ç¬¬ %d é¡µæ•°æ®éªŒè¯å¤±è´¥: %s", page_index, error_msg)
                        break
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦å·²è·å–åˆ°æœ¬åœ°æœ€æ–°æ•°æ®ä¹‹å‰çš„æ•°æ®
                if latest_local_date:
                    new_df_page = df_page[df_page['date'].dt.date > latest_local_date]
                    if new_df_page.empty:
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”ä¹‹å‰å·²ç»å‘ç°è¿‡æ–°æ•°æ®ï¼Œåˆ™åœæ­¢çˆ¬å–
                        if has_new_data:
                            logger.info("åŸºé‡‘ %s å·²è·å–æ‰€æœ‰æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", fund_code)
                            break
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æ˜¯ç¬¬ä¸€é¡µï¼Œåˆ™è¯´æ˜æ²¡æœ‰æ–°æ•°æ®
                        elif page_index == 1:
                            logger.info("åŸºé‡‘ %s æ— æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", fund_code)
                            break
                    else:
                        has_new_data = True
                        all_new_data.append(new_df_page)
                        logger.info("ç¬¬ %d é¡µ: å‘ç° %d è¡Œæ–°æ•°æ®", page_index, len(new_df_page))
                else:
                    # å¦‚æœæ˜¯é¦–æ¬¡ä¸‹è½½ï¼Œåˆ™è·å–æ‰€æœ‰æ•°æ®
                    all_new_data.append(df_page)

                logger.info("åŸºé‡‘ %s æ€»é¡µæ•°: %d, å½“å‰é¡µ: %d, å½“å‰é¡µè¡Œæ•°: %d", fund_code, total_pages, page_index, len(df_page))
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œä¸”å½“å‰é¡µæ•°æ®æ¯”æœ€æ–°æ•°æ®æ—¥æœŸæ—©ï¼Œåˆ™ç»“æŸå¾ªç¯
                if latest_local_date and (df_page['date'].dt.date <= latest_local_date).any():
                    logger.info("åŸºé‡‘ %s å·²è¿½æº¯åˆ°æœ¬åœ°æ•°æ®ï¼Œå¢é‡çˆ¬å–ç»“æŸã€‚", fund_code)
                    break

                if page_index >= total_pages:
                    logger.info("åŸºé‡‘ %s å·²è·å–æ‰€æœ‰å†å²æ•°æ®ï¼Œå…± %d é¡µï¼Œçˆ¬å–ç»“æŸ", fund_code, total_pages)
                    break
                
                page_index += 1
                time_module.sleep(random.uniform(1, 2))  # ä½¿ç”¨é…ç½®çš„sleepæ—¶é—´
                
            except requests.exceptions.RequestException as e:
                logger.error("åŸºé‡‘ %s APIè¯·æ±‚å¤±è´¥: %s", fund_code, str(e))
                raise
            except Exception as e:
                logger.error("åŸºé‡‘ %s APIæ•°æ®è§£æå¤±è´¥: %s", fund_code, str(e))
                raise

        # åˆå¹¶æ–°æ•°æ®å¹¶è¿”å›
        if all_new_data:
            new_combined_df = pd.concat(all_new_data, ignore_index=True)
            # éªŒè¯åˆå¹¶åçš„æ•°æ®
            is_valid, error_msg = self._validate_fund_data(new_combined_df, fund_code)
            if not is_valid:
                logger.error("åˆå¹¶åçš„æ–°æ•°æ®éªŒè¯å¤±è´¥: %s", error_msg)
                return pd.DataFrame()
            return new_combined_df[['date', 'net_value']]
        else:
            return pd.DataFrame()

    def _calculate_indicators(self, df):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¹¶ç”Ÿæˆç»“æœå­—å…¸"""
        if df is None or df.empty or len(df) < self.min_data_points:
            return None

        df = df.sort_values(by='date', ascending=True)
        
        # MACD - ä½¿ç”¨é…ç½®å‚æ•°
        exp_fast = df['net_value'].ewm(span=12, adjust=False).mean()
        exp_slow = df['net_value'].ewm(span=26, adjust=False).mean()
        df['macd'] = exp_fast - exp_slow
        df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()

        # å¸ƒæ—å¸¦ - ä½¿ç”¨é…ç½®å‚æ•°
        df['bb_mid'] = df['net_value'].rolling(window=20, min_periods=1).mean()
        df['bb_std'] = df['net_value'].rolling(window=20, min_periods=1).std()
        df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * 2)
        df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * 2)
        
        # RSI - ä½¿ç”¨é…ç½®å‚æ•°
        delta = df['net_value'].diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        
        avg_gain = gain.rolling(window=14, min_periods=1).mean()
        avg_loss = loss.rolling(window=14, min_periods=1).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.nan)
        df['rsi'] = 100 - (100 / (1 + rs))

        # MA - ä½¿ç”¨é…ç½®å‚æ•°
        df['ma50'] = df['net_value'].rolling(window=min(50, len(df)), min_periods=1).mean()
        df['ma_ratio'] = df['net_value'] / df['ma50']

        return df
        
    def _analyze_index(self, index_df):
        """åˆ†æå¤§ç›˜æŒ‡æ•°ï¼Œç”ŸæˆæŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºæƒ…ç»ªä¿¡å·"""
        if index_df.empty or len(index_df) < self.min_data_points:
            logger.warning("å¤§ç›˜æŒ‡æ•°æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
            return None
        
        processed_index_df = self._calculate_indicators(index_df)
        latest_data = processed_index_df.iloc[-1]
        
        latest_net_value = latest_data['net_value']
        latest_rsi = latest_data['rsi']
        latest_ma_ratio = latest_data['ma_ratio']
        latest_macd_diff = latest_data['macd'] - latest_data['signal']
        
        # ç”Ÿæˆå¤§ç›˜ä¿¡å·
        index_advice = "è§‚å¯Ÿ"
        if (not np.isnan(latest_rsi) and latest_rsi > 70) or \
           (not np.isnan(latest_ma_ratio) and latest_ma_ratio > 1.2):
            index_advice = "ç­‰å¾…å›è°ƒ"
        elif (not np.isnan(latest_rsi) and latest_rsi < 30) or \
             (not np.isnan(latest_ma_ratio) and latest_ma_ratio < 0.8):
            index_advice = "å¯åˆ†æ‰¹ä¹°å…¥"
            
        index_action_signal = "æŒæœ‰/è§‚å¯Ÿ"
        if not np.isnan(latest_ma_ratio) and latest_ma_ratio < 0.95:
            index_action_signal = "å¼ºå–å‡º/è§„é¿"
        elif (not np.isnan(latest_rsi) and latest_rsi > 65) or \
             (not np.isnan(latest_ma_ratio) and latest_ma_ratio > 1.2):
            index_action_signal = "å¼±å–å‡º/è§„é¿"
        elif (not np.isnan(latest_rsi) and latest_rsi < 35) or \
             (not np.isnan(latest_ma_ratio) and latest_ma_ratio < 0.9):
            index_action_signal = "å¼ºä¹°å…¥"
        elif (not np.isnan(latest_rsi) and latest_rsi < 45) or \
             (not np.isnan(latest_ma_ratio) and latest_ma_ratio < 1.0):
            index_action_signal = "å¼±ä¹°å…¥"

        index_signals = {
            'latest_net_value': latest_net_value,
            'rsi': latest_rsi,
            'ma_ratio': latest_ma_ratio,
            'advice': index_advice,
            'action_signal': index_action_signal
        }
        return index_signals
    
    def _get_latest_signals(self, fund_code, df):
        """æ ¹æ®æœ€æ–°æ•°æ®è®¡ç®—ä¿¡å·"""
        try:
            processed_df = self._calculate_indicators(df)
            if processed_df is None:
                logger.warning("åŸºé‡‘ %s æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®¡ç®—", fund_code)
                return {
                    'fund_code': fund_code, 'latest_net_value': "æ•°æ®è·å–å¤±è´¥", 'rsi': np.nan, 'ma_ratio': np.nan,
                    'macd_diff': np.nan, 'bb_upper': np.nan, 'bb_lower': np.nan, 'bb_position': 'N/A', 'advice': "è§‚å¯Ÿ", 'action_signal': 'N/A'
                }
            
            latest_data = processed_df.iloc[-1]
            latest_net_value = latest_data['net_value']
            latest_rsi = latest_data['rsi']
            latest_ma50_ratio = latest_data['ma_ratio']
            latest_macd_diff = latest_data['macd'] - latest_data['signal']
            latest_bb_upper = latest_data['bb_upper']
            latest_bb_lower = latest_data['bb_lower']

            advice = "è§‚å¯Ÿ"
            if (not np.isnan(latest_rsi) and latest_rsi > 70) or \
               (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
               (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2):
                advice = "ç­‰å¾…å›è°ƒ"
            elif (not np.isnan(latest_rsi) and latest_rsi < 30) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.8):
                advice = "å¯åˆ†æ‰¹ä¹°å…¥"
            elif (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                advice = "å¯åˆ†æ‰¹ä¹°å…¥"
            elif (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 1) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff < 0):
                advice = "ç­‰å¾…å›è°ƒ"

            action_signal = "æŒæœ‰/è§‚å¯Ÿ"
            if not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.95:
                action_signal = "å¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 65) or \
                 (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2):
                action_signal = "å¼±å–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi < 35) and \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.9) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                action_signal = "å¼ºä¹°å…¥"
            elif (not np.isnan(latest_rsi) and latest_rsi < 45) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 1.0):
                action_signal = "å¼±ä¹°å…¥"

            # è®¡ç®—å¸ƒæ—å¸¦ä½ç½®
            bb_position = "ä¸­è½¨"
            if not np.isnan(latest_net_value) and not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper:
                bb_position = "ä¸Šè½¨ä¸Šæ–¹"
            elif not np.isnan(latest_net_value) and not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower:
                bb_position = "ä¸‹è½¨ä¸‹æ–¹"

            return {
                'fund_code': fund_code, 'latest_net_value': latest_net_value, 'rsi': latest_rsi, 'ma_ratio': latest_ma50_ratio,
                'macd_diff': latest_macd_diff, 'bb_upper': latest_bb_upper, 'bb_lower': latest_bb_lower, 'bb_position': bb_position,
                'advice': advice, 'action_signal': action_signal
            }
        except Exception as e:
            logger.error("å¤„ç†åŸºé‡‘ %s æ—¶å‘ç”Ÿå¼‚å¸¸: %s", fund_code, str(e))
            return {
                'fund_code': fund_code, 'latest_net_value': "æ•°æ®è·å–å¤±è´¥", 'rsi': np.nan, 'ma_ratio': np.nan,
                'macd_diff': np.nan, 'bb_upper': np.nan, 'bb_lower': np.nan, 'bb_position': 'N/A', 
                'advice': "è§‚å¯Ÿ", 'action_signal': 'N/A'
            }

    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„åŸºé‡‘æŠ€æœ¯æŒ‡æ ‡æŠ¥å‘Š"""
        logger.info("å¼€å§‹ç”Ÿæˆè¯¦ç»†çš„åŸºé‡‘æŠ€æœ¯æŒ‡æ ‡æŠ¥å‘Š...")
        
        all_fund_data = []
        for fund_code in self.fund_codes:
            data = self.fund_data.get(fund_code)
            if data and data['latest_net_value'] != "æ•°æ®è·å–å¤±è´¥":
                all_fund_data.append(data)
        
        if not all_fund_data:
            logger.warning("æ²¡æœ‰å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„åŸºé‡‘æ•°æ®ã€‚")
            with open(self.output_file, 'w', encoding='utf-8') as f:
                f.write(f"# å¸‚åœºç›‘æ§æŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d')})\n\n")
                f.write("---")
                f.write("## åŸºé‡‘æ•°æ®åˆ†æ\n\n")
                f.write("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆåŸºé‡‘æ•°æ®ã€‚\n\n")
            return

        all_fund_data_df = pd.DataFrame(all_fund_data)
        
        # æ’åº
        # åˆ›å»ºä¸€ä¸ªæ’åºé”®
        action_signal_order = {
            'å¼ºä¹°å…¥': 0,
            'å¼±ä¹°å…¥': 1,
            'æŒæœ‰/è§‚å¯Ÿ': 2,
            'ç­‰å¾…å›è°ƒ': 3,
            'å¼±å–å‡º/è§„é¿': 4,
            'å¼ºå–å‡º/è§„é¿': 5,
            'N/A': 6
        }
        all_fund_data_df['action_signal_order'] = all_fund_data_df['action_signal'].map(action_signal_order)
        all_fund_data_df = all_fund_data_df.sort_values(by='action_signal_order', ascending=True)

        # æ ¼å¼åŒ–æ•°æ®ä»¥ç”¨äºæŠ¥å‘Š
        df_for_report = all_fund_data_df[['fund_code', 'latest_net_value', 'rsi', 'ma_ratio', 'macd_diff', 'bb_position', 'advice', 'action_signal']].copy()
        df_for_report.rename(columns={
            'fund_code': 'åŸºé‡‘ä»£ç ',
            'latest_net_value': 'æœ€æ–°å‡€å€¼',
            'rsi': 'RSI',
            'ma_ratio': 'MA50æ¯”ä¾‹',
            'macd_diff': 'MACDä¿¡å·',
            'bb_position': 'å¸ƒæ—å¸¦ä½ç½®',
            'advice': 'å»ºè®®',
            'action_signal': 'æ“ä½œä¿¡å·'
        }, inplace=True)
        
        df_for_report['RSI'] = df_for_report['RSI'].round(2)
        df_for_report['MA50æ¯”ä¾‹'] = df_for_report['MA50æ¯”ä¾‹'].round(2)
        df_for_report['æœ€æ–°å‡€å€¼'] = df_for_report['æœ€æ–°å‡€å€¼'].round(4)
        
        # å°†MACDä¿¡å·è½¬æ¢ä¸ºâ€œé‡‘å‰â€æˆ–â€œæ­»å‰â€
        df_for_report['MACDä¿¡å·'] = df_for_report['MACDä¿¡å·'].apply(lambda x: 'é‡‘å‰' if x > 0 else 'æ­»å‰' if x < 0 else 'N/A')
        
        markdown_table = df_for_report.to_markdown(index=False)
        
        # è·å–å¤§ç›˜æŒ‡æ•°ä¿¡å·
        index_signals = self._analyze_index(self.index_df)

        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write(f"# å¸‚åœºç›‘æ§æŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d')})\n\n")
            f.write("---\n")
            if index_signals:
                f.write(f"### å¤§ç›˜æŒ‡æ•° {self.index_code} å¸‚åœºæƒ…ç»ª\n\n")
                f.write(f"ğŸ“ˆ **æœ€æ–°å‡€å€¼**: {index_signals['latest_net_value']:.2f}\n")
                f.write(f"ğŸ“Š **RSI**: {index_signals['rsi']:.2f}\n")
                f.write(f"ğŸ“‰ **MA_Ratio**: {index_signals['ma_ratio']:.2f}\n")
                f.write(f"ğŸ’¡ **å½“å‰ä¿¡å·**: {index_signals['action_signal']} | {index_signals['advice']}\n")
            f.write("---\n")
            f.write(f"## æ¨èåŸºé‡‘æŠ€æœ¯æŒ‡æ ‡\n")
            f.write(f"æ­¤è¡¨æ ¼å·²æŒ‰**è¡ŒåŠ¨ä¿¡å·ä¼˜å…ˆçº§**æ’åºï¼Œ'å¼ºä¹°å…¥'åŸºé‡‘å°†æ’åœ¨æœ€å‰é¢ã€‚\n\n")
            f.write(markdown_table)
            f.write("\n\n")

        logger.info("è¯¦ç»†åŸºé‡‘æŠ€æœ¯æŒ‡æ ‡æŠ¥å‘Šå·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°: %s", self.output_file)
        
    def _get_portfolio_signals(self, fund_data, max_positions=None):
        """æ ¹æ®ä¹°å…¥ä¿¡å·å¯¹åŸºé‡‘è¿›è¡Œè¯„åˆ†å’Œæ’å"""
        if not fund_data:
            return pd.DataFrame(), pd.DataFrame()

        df = pd.DataFrame(fund_data)
        
        # 1. è¿‡æ»¤å‡ºå…·æœ‰â€œä¹°å…¥â€ä¿¡å·çš„åŸºé‡‘
        buy_signals = ['å¼ºä¹°å…¥', 'å¼±ä¹°å…¥']
        buy_candidates = df[df['action_signal'].isin(buy_signals)].copy()
        
        if buy_candidates.empty:
            return pd.DataFrame(), pd.DataFrame()

        # 2. è®¡ç®—ç»¼åˆä¹°å…¥è¯„åˆ†
        buy_candidates['buy_score'] = buy_candidates.apply(self._calculate_buy_score, axis=1)
        
        # 3. æŒ‰è¯„åˆ†å’Œä¿¡å·æ’åºï¼Œé€‰å‡ºæœ€ä½³åŸºé‡‘
        buy_candidates = buy_candidates.sort_values(
            by=['action_signal', 'buy_score', 'rsi'],
            ascending=[False, False, True]
        ).reset_index(drop=True)
        
        # æ ¹æ®é…ç½®é™åˆ¶æœ€å¤§æŒä»“æ•°
        if max_positions:
            buy_candidates = buy_candidates.head(max_positions)

        # 4. å»ºè®®åˆ†é…
        if not buy_candidates.empty:
            num_positions = len(buy_candidates)
            suggested_allocation = 100 / num_positions
            buy_candidates['suggested_allocation'] = suggested_allocation
            buy_candidates['å»ºè®®åˆ†é…'] = buy_candidates['suggested_allocation'].apply(lambda x: f'{x:.2f} å…ƒ')

        return buy_candidates, df
    
    def _calculate_buy_score(self, data):
        """è®¡ç®—ä¹°å…¥è¯„åˆ†"""
        score = 0
        if not np.isnan(data['rsi']) and data['rsi'] < 35:
            score += 50
        elif not np.isnan(data['rsi']) and data['rsi'] < 45:
            score += 30
        
        if not np.isnan(data['ma_ratio']) and data['ma_ratio'] < 0.9:
            score += 50
        elif not np.isnan(data['ma_ratio']) and data['ma_ratio'] < 1.0:
            score += 30
            
        if not np.isnan(data['macd_diff']) and data['macd_diff'] > 0:
            score += 20
        
        return score

    def run(self):
        """ä¸»æ‰§è¡Œå‡½æ•°ï¼Œåè°ƒæ•´ä¸ªæµç¨‹"""
        try:
            # 1. è§£ææŠ¥å‘Šä»¥è·å–åŸºé‡‘åˆ—è¡¨
            self._parse_report()

            if not self.fund_codes:
                logger.error("æ— æ³•è·å–åŸºé‡‘åˆ—è¡¨ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
                return
            
            # 2. åŠ è½½å¤§ç›˜æŒ‡æ•°æ•°æ®
            self._load_index_data_from_file()

            # 3. å¤šçº¿ç¨‹å¤„ç†æ¯ä¸ªåŸºé‡‘
            with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                # ä½¿ç”¨å­—å…¸å­˜å‚¨ futures ä»¥ä¾¿æ˜ å°„å›åŸºé‡‘ä»£ç 
                future_to_fund = {executor.submit(self._process_single_fund, fund_code): fund_code for fund_code in self.fund_codes}
                
                for future in concurrent.futures.as_completed(future_to_fund):
                    fund_code = future_to_fund[future]
                    try:
                        result = future.result()
                        if result:
                            self.fund_data[fund_code] = result
                    except Exception as e:
                        logger.error("å¤„ç†åŸºé‡‘ %s å¤±è´¥: %s", fund_code, e)
            
            # 4. ç”ŸæˆæŠ¥å‘Š
            self.generate_detailed_report()
            
        except Exception as e:
            logger.exception("è„šæœ¬æ‰§è¡Œå¤±è´¥: %s", e)

if __name__ == '__main__':
    monitor = MarketMonitor()
    monitor.run()
